{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pytorch_model.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMLDJMwRAlrsAFjxdA3QUQs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"HsZb7QICuRIe","colab_type":"code","outputId":"e4fa48a2-0f42-45ad-d61a-c8fe0f19119d","executionInfo":{"status":"ok","timestamp":1591014133247,"user_tz":-120,"elapsed":49153,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}},"colab":{"base_uri":"https://localhost:8080/","height":469}},"source":["!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py > /dev/null\n","!python pytorch-xla-env-setup.py --version 20200515 --apt-packages libomp5 libopenblas-dev > /dev/null\n","!pip install transformers==2.5.1 > /dev/null\n","!pip install pandarallel > /dev/null\n","!pip install catalyst==20.4.2 > /dev/null\n","!pip install kaggle\n","!pip install emoji"],"execution_count":1,"outputs":[{"output_type":"stream","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  4264  100  4264    0     0  53300      0 --:--:-- --:--:-- --:--:-- 53300\n","Copying gs://tpu-pytorch/wheels/torch-nightly+20200515-cp36-cp36m-linux_x86_64.whl...\n","- [1 files][ 91.0 MiB/ 91.0 MiB]                                                \n","Operation completed over 1 objects/91.0 MiB.                                     \n","Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200515-cp36-cp36m-linux_x86_64.whl...\n","- [1 files][119.5 MiB/119.5 MiB]                                                \n","Operation completed over 1 objects/119.5 MiB.                                    \n","Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200515-cp36-cp36m-linux_x86_64.whl...\n","/ [1 files][  2.3 MiB/  2.3 MiB]                                                \n","Operation completed over 1 objects/2.3 MiB.                                      \n","\u001b[31mERROR: fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\n","\u001b[31mERROR: catalyst 20.4.2 requires torchvision>=0.2.1, which is not installed.\u001b[0m\n","Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.4.5.1)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n","Requirement already satisfied: emoji in /usr/local/lib/python3.6/dist-packages (0.5.4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lfxkXZQf1nLt","colab_type":"code","colab":{}},"source":["# arr=[]\n","# while(1):\n","#  arr.append(1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IIWDJmzxhtM9","colab_type":"code","outputId":"bc30aea4-de03-45a8-a8ff-819d058748f3","executionInfo":{"status":"ok","timestamp":1591014137739,"user_tz":-120,"elapsed":53211,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["%load_ext autoreload\n","%autoreload 2 \n","\n","from google.colab import drive\n","\n","drive.mount(\"/content/drive\", force_remount=True)\n","\n","import sys\n","sys.path.append('drive/My Drive/toxic_comment/scripts')\n","\n","import os\n","os.environ['XLA_USE_BF16'] = \"1\"\n","\n","import gc\n","import time\n","import json\n","import random\n","from pathlib import Path\n","from importlib import reload\n","\n","import utility as utils\n","import albumentations as alb\n","import data_cleaning as clean\n","import models\n","import config\n","\n","reload(utils)\n","reload(alb)\n","reload(clean)\n","reload(models)\n","reload(config)\n","\n","\n","import numpy as np\n","import pandas as pd\n","from transformers import AutoModel, AutoTokenizer\n","from tqdm import tqdm\n","tqdm.pandas()\n","\n","from pandarallel import pandarallel\n","\n","import torch\n","from torch.utils.data import DataLoader\n","import torch_xla.core.xla_model as xm\n","import torch_xla.distributed.xla_multiprocessing as xmp\n","from catalyst.data.sampler import DistributedSamplerWrapper, BalanceClassSampler\n","\n","pandarallel.initialize(nb_workers=4, progress_bar=False)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","INFO: Pandarallel will run on 4 workers.\n","INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J9iEdfKAzU0q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"5ef8a0b9-82ac-4250-fd0e-67ecd1bd31b7","executionInfo":{"status":"ok","timestamp":1591014137742,"user_tz":-120,"elapsed":52374,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}}},"source":["root_dir = \"drive/My Drive/toxic_comment\"\n","\n","# *Git related variables\n","\n","GIT_REPOSITORY = \"toxic-comment\" \n","GIT_CREDENTIALS = Path(root_dir, \"credentials/git_creds.json\")\n","\n","def git_path():\n","  with open(GIT_CREDENTIALS) as cred_json:\n","    creds = json.load(cred_json)\n","\n","  GIT_PATH = \"https://\" + creds['token'] + \"@github.com/\" + creds['username'] + \"/\" + GIT_REPOSITORY + \".git\"\n","  print(f'GIT_PATH: {GIT_PATH}')\n","\n","  return GIT_PATH, creds['email'], creds['username']\n","\n","GIT_PATH, GIT_EMAIL, GIT_USERNAME = git_path()\n","\n","\n","# *Model related variables\n","SEED = 42\n","MODEL = 'xlm-roberta-large'\n","MODEL_VERSION = 'v1'\n","MAX_LENGTH = 224\n","\n","LANGS = {\n","    'en': 'english',\n","    'it': 'italian', \n","    'fr': 'french', \n","    'es': 'spanish',\n","    'tr': 'turkish', \n","    'ru': 'russian',\n","    'pt': 'portuguese'\n","}\n","\n","# *Data access\n","data_dir = Path(root_dir, \"data\")\n","data_t_dir = data_dir/\"jigsaw-toxic/translations\"\n","\n","# *Model paths\n","model_base_dir = Path(root_dir, \"models\")\n","model_dir = (model_base_dir/MODEL/MODEL_VERSION)\n","\n","# *Files\n","train_file1 = \"jigsaw-toxic/jigsaw-toxic-comment-train.csv\"\n","train_file2 = \"jigsaw-toxic/jigsaw-unintended-bias-train.csv\"\n","val_file = \"jigsaw-toxic/validation.csv\"\n","test_file = \"jigsaw-toxic/test.csv\"\n","sub_file = \"jigsaw-toxic/sample_submission.csv\"\n","open_subtitles_file = 'open-subtitles-toxic/open-subtitles-synthesic.csv'\n","\n","out_dir = Path(root_dir, 'output')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["GIT_PATH: https://5ee99ff256ca8a15f73f1b37d96c87ebed5facc6@github.com/quancore/toxic-comment.git\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mPuE1HQMhVNU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"outputId":"d33beca4-7350-47e5-d090-b53121060d3a","executionInfo":{"status":"ok","timestamp":1591012600000,"user_tz":-120,"elapsed":4428,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}}},"source":["!git clone \"{GIT_PATH}\" ./temp      # clone github repository to temp folder\n","!mv ./temp/.git \"{root_dir}/.git\"       # move all files/folders in temp folder to folder defined in project path\n","!rm -rf ./temp                      # remove all the files/folders in temp folder"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Cloning into './temp'...\n","remote: Enumerating objects: 6, done.\u001b[K\n","remote: Counting objects:  16% (1/6)\u001b[K\rremote: Counting objects:  33% (2/6)\u001b[K\rremote: Counting objects:  50% (3/6)\u001b[K\rremote: Counting objects:  66% (4/6)\u001b[K\rremote: Counting objects:  83% (5/6)\u001b[K\rremote: Counting objects: 100% (6/6)\u001b[K\rremote: Counting objects: 100% (6/6), done.\u001b[K\n","remote: Compressing objects:  25% (1/4)\u001b[K\rremote: Compressing objects:  50% (2/4)\u001b[K\rremote: Compressing objects:  75% (3/4)\u001b[K\rremote: Compressing objects: 100% (4/4)\u001b[K\rremote: Compressing objects: 100% (4/4), done.\u001b[K\n","remote: Total 6 (delta 0), reused 3 (delta 0), pack-reused 0\u001b[K\n","Unpacking objects:  16% (1/6)   \rUnpacking objects:  33% (2/6)   \rUnpacking objects:  50% (3/6)   \rUnpacking objects:  66% (4/6)   \rUnpacking objects:  83% (5/6)   \rUnpacking objects: 100% (6/6)   \rUnpacking objects: 100% (6/6), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"im4lCmzD1dx_","colab_type":"code","colab":{}},"source":["def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","\n","seed_everything(SEED)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O-hcJSL1hxdC","colab_type":"code","outputId":"84ee08e3-a247-49e8-dff8-e62b2883bd44","executionInfo":{"status":"ok","timestamp":1590951650439,"user_tz":-120,"elapsed":115176,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}},"colab":{"base_uri":"https://localhost:8080/","height":173}},"source":["%%time\n","# Read the data and external sources\n","dir_dict = {'base_dir': data_dir, 'base_t_dir': data_t_dir, 'train_file1': train_file1, \n","            'train_file2': train_file2, 'val_file': val_file, 'test_file': test_file, 'sub_file': sub_file}\n","train, valid, test, sub = utils.read_data(dir_dict, list(LANGS.keys()))\n","external = utils.read_external_data((data_dir/'external'), list(LANGS.values()))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Translation has not found: drive/My Drive/toxic_comment/data/jigsaw-toxic/translations/jigsaw-toxic-comment-train-google-en-cleaned.csv\n","File not found: drive/My Drive/toxic_comment/data/external/english-external-cleaned.csv\n","File not found: drive/My Drive/toxic_comment/data/external/italian-external-cleaned.csv\n","File not found: drive/My Drive/toxic_comment/data/external/french-external-cleaned.csv\n","File not found: drive/My Drive/toxic_comment/data/external/spanish-external-cleaned.csv\n","File not found: drive/My Drive/toxic_comment/data/external/russian-external-cleaned.csv\n","File not found: drive/My Drive/toxic_comment/data/external/portuguese-external-cleaned.csv\n","CPU times: user 45.3 s, sys: 4.43 s, total: 49.8 s\n","Wall time: 1min 4s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z7_j4LVuyPay","colab_type":"code","outputId":"74f180b3-ce9d-4e04-a4f8-c01d321e556d","executionInfo":{"status":"ok","timestamp":1590951650646,"user_tz":-120,"elapsed":115374,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}},"colab":{"base_uri":"https://localhost:8080/","height":878}},"source":["train"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>comment_text</th>\n","      <th>toxic</th>\n","      <th>severe_toxic</th>\n","      <th>obscene</th>\n","      <th>threat</th>\n","      <th>insult</th>\n","      <th>identity_hate</th>\n","      <th>severe_toxicity</th>\n","      <th>identity_attack</th>\n","      <th>asian</th>\n","      <th>atheist</th>\n","      <th>bisexual</th>\n","      <th>black</th>\n","      <th>buddhist</th>\n","      <th>christian</th>\n","      <th>female</th>\n","      <th>heterosexual</th>\n","      <th>hindu</th>\n","      <th>homosexual_gay_or_lesbian</th>\n","      <th>intellectual_or_learning_disability</th>\n","      <th>jewish</th>\n","      <th>latino</th>\n","      <th>male</th>\n","      <th>muslim</th>\n","      <th>other_disability</th>\n","      <th>other_gender</th>\n","      <th>other_race_or_ethnicity</th>\n","      <th>other_religion</th>\n","      <th>other_sexual_orientation</th>\n","      <th>physical_disability</th>\n","      <th>psychiatric_or_mental_illness</th>\n","      <th>transgender</th>\n","      <th>white</th>\n","      <th>created_date</th>\n","      <th>publication_id</th>\n","      <th>parent_id</th>\n","      <th>article_id</th>\n","      <th>rating</th>\n","      <th>funny</th>\n","      <th>wow</th>\n","      <th>sad</th>\n","      <th>likes</th>\n","      <th>disagree</th>\n","      <th>sexual_explicit</th>\n","      <th>identity_annotator_count</th>\n","      <th>toxicity_annotator_count</th>\n","      <th>lang</th>\n","      <th>Unnamed: 0</th>\n","      <th>Unnamed: 0.1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0000997932d777bf</td>\n","      <td>Explanation\\nWhy the edits made under my usern...</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>en</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000103f0d9cfb60f</td>\n","      <td>D'aww! He matches this background colour I'm s...</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>en</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>000113f07ec002fd</td>\n","      <td>Hey man, I'm really not trying to edit war. It...</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>en</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0001b41b1c6bb37e</td>\n","      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>en</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0001d958c54c6e35</td>\n","      <td>You, sir, are my hero. Any chance you remember...</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>en</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>223389</th>\n","      <td>ffeb7faf9662ed0f</td>\n","      <td>(UTC)\\n\\n :: FYI, atualmente estou em conflito...</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>pt</td>\n","      <td>223544.0</td>\n","      <td>223544.0</td>\n","    </tr>\n","    <tr>\n","      <th>223390</th>\n","      <td>ffe3a3e2d8f0eb9b</td>\n","      <td>Esta é a minha sandbox da página de discussão ...</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>pt</td>\n","      <td>223545.0</td>\n","      <td>223545.0</td>\n","    </tr>\n","    <tr>\n","      <th>223391</th>\n","      <td>ffebe90c8d5acaba</td>\n","      <td>\"\\n\\n == IRAN ==\\n Isso mesmo, Irã. Foi o noss...</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>pt</td>\n","      <td>223546.0</td>\n","      <td>223546.0</td>\n","    </tr>\n","    <tr>\n","      <th>223392</th>\n","      <td>fff23c3e174e895e</td>\n","      <td>\"\\n li esta página de discussão e fiquei impre...</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>pt</td>\n","      <td>223547.0</td>\n","      <td>223547.0</td>\n","    </tr>\n","    <tr>\n","      <th>223393</th>\n","      <td>fff3ae2e177b6bb3</td>\n","      <td>\"\\n\\n == Mesma cafeteria? ==\\n\\n Minha memória...</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>pt</td>\n","      <td>223548.0</td>\n","      <td>223548.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3431579 rows × 50 columns</p>\n","</div>"],"text/plain":["                      id  ... Unnamed: 0.1\n","0       0000997932d777bf  ...          NaN\n","1       000103f0d9cfb60f  ...          NaN\n","2       000113f07ec002fd  ...          NaN\n","3       0001b41b1c6bb37e  ...          NaN\n","4       0001d958c54c6e35  ...          NaN\n","...                  ...  ...          ...\n","223389  ffeb7faf9662ed0f  ...     223544.0\n","223390  ffe3a3e2d8f0eb9b  ...     223545.0\n","223391  ffebe90c8d5acaba  ...     223546.0\n","223392  fff23c3e174e895e  ...     223547.0\n","223393  fff3ae2e177b6bb3  ...     223548.0\n","\n","[3431579 rows x 50 columns]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"_yoQXP4YPcmP","colab_type":"code","outputId":"b403deeb-b31a-4fd2-d167-2d300f217e9c","executionInfo":{"status":"ok","timestamp":1590951651800,"user_tz":-120,"elapsed":116523,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}},"colab":{"base_uri":"https://localhost:8080/","height":276}},"source":["train['lang'].hist(bins=20);"],"execution_count":8,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"H4p0Mp8qMxGo","colab_type":"code","outputId":"633f44a8-d3d2-46fc-fdcc-91482c97ddd4","executionInfo":{"status":"ok","timestamp":1590951652409,"user_tz":-120,"elapsed":117125,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["train['comment_text'].isna().sum()"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"-Uoz_VGI1Tmh","colab_type":"code","outputId":"2e6ea44e-a13d-42ba-f0dd-5de104d76d17","executionInfo":{"status":"ok","timestamp":1590951652410,"user_tz":-120,"elapsed":117121,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}},"colab":{"base_uri":"https://localhost:8080/","height":455}},"source":["valid"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>comment_text</th>\n","      <th>lang</th>\n","      <th>toxic</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Este usuario ni siquiera llega al rango de    ...</td>\n","      <td>es</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Il testo di questa voce pare esser scopiazzato...</td>\n","      <td>it</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Vale. Sólo expongo mi pasado. Todo tiempo pasa...</td>\n","      <td>es</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Bu maddenin alt başlığı olarak  uluslararası i...</td>\n","      <td>tr</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Belçika nın şehirlerinin yanında ilçe ve belde...</td>\n","      <td>tr</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7995</th>\n","      <td>Il fatto è che la pagina dei personaggi minor...</td>\n","      <td>it</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7996</th>\n","      <td>El imbesil ete dela luna no se entera ni ostia...</td>\n","      <td>es</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7997</th>\n","      <td>olum sız manyakmısınz siz adam sıze sanal yıld...</td>\n","      <td>tr</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7998</th>\n","      <td>El mapa del reinado de Alhaken esta ligerament...</td>\n","      <td>es</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7999</th>\n","      <td>lasciami la tua email per favore. ad ogni modo...</td>\n","      <td>it</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8000 rows × 3 columns</p>\n","</div>"],"text/plain":["                                           comment_text lang  toxic\n","id                                                                 \n","0     Este usuario ni siquiera llega al rango de    ...   es      0\n","1     Il testo di questa voce pare esser scopiazzato...   it      0\n","2     Vale. Sólo expongo mi pasado. Todo tiempo pasa...   es      1\n","3     Bu maddenin alt başlığı olarak  uluslararası i...   tr      0\n","4     Belçika nın şehirlerinin yanında ilçe ve belde...   tr      0\n","...                                                 ...  ...    ...\n","7995   Il fatto è che la pagina dei personaggi minor...   it      0\n","7996  El imbesil ete dela luna no se entera ni ostia...   es      1\n","7997  olum sız manyakmısınz siz adam sıze sanal yıld...   tr      1\n","7998  El mapa del reinado de Alhaken esta ligerament...   es      0\n","7999  lasciami la tua email per favore. ad ogni modo...   it      0\n","\n","[8000 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"VErT41jaH8h6","colab_type":"code","outputId":"7fd56f6e-447e-473c-8a3f-4ce315fb50ed","executionInfo":{"status":"ok","timestamp":1590951652412,"user_tz":-120,"elapsed":117116,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["external.head(50)"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","      <th>toxic</th>\n","      <th>lang</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>20948</td>\n","      <td>en güzel uyuyan insan ödülü jeon jungkooka gid...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10134</td>\n","      <td>mekanı cennet olsun  saygılar sayın avukatımız...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>23457</td>\n","      <td>kızlar aranızda kas yığını beylere düşenler ol...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>18401</td>\n","      <td>biraz ders çalışayım  tembellik ve uyku düşman...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>17525</td>\n","      <td>trezeguet yerine el sharawy daha iyi olmaz mı</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>11996</td>\n","      <td>bence de olması gerekiyor  hatta meslek lisesi...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>38452</td>\n","      <td>mutlu görünümlü ama daima mutsuz olanlar burad...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>12615</td>\n","      <td>liraya traş oldum arkadaşım diyor ki ne kesiyo...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>13520</td>\n","      <td>reis bu ülkenin devlet başkanı ve ak parti gen...</td>\n","      <td>1</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>45562</td>\n","      <td>var olan  ancak düşünüldüğü kadarıyla vardır  ...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>20724</td>\n","      <td>şu kodumun sitesine günlerce giremeyecek kadar...</td>\n","      <td>1</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>24529</td>\n","      <td>buralara değil yaz günü  kışın bile kar yağmıyor</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>13853</td>\n","      <td>prodüktivite arz cazibesi tolerans kolacı tomr...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>15493</td>\n","      <td>muavinlerini arabı çıkar bozuk olur öyle bide ...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>13276</td>\n","      <td>yalnız bunlar harabe bir yerdeler ne işleri va...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>44185</td>\n","      <td>bundan sonra katiyen arkadaşlarıma dışarı çıka...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>10647</td>\n","      <td>aracı ekürisinin en kötü tayı bile olsa bursa ...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>37568</td>\n","      <td>bin euro ya deportivo da oynuyordu  şimdi  mil...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>15984</td>\n","      <td>aşk ödü evvel düşer maşuka  andan aşıka  sami ...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>20290</td>\n","      <td>bundan yıl sonrayaptıklarından çok yapmadığın ...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>46099</td>\n","      <td>aşk ile ölmeden toprak olanlar canım yunus  k...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>43375</td>\n","      <td>çıkış birkaç kere yapman lazım  aslında bir ta...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>44928</td>\n","      <td>affetmek ve unutmak iyi insanların intikamıdır</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>26789</td>\n","      <td>eleştirebilirsin beğenmeyebilirsin siyasi görü...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>20741</td>\n","      <td>aşkta öyle bir şey olsa gerek</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>26141</td>\n","      <td>nasıl o    çocuklarıyla aynı devre denk geldik</td>\n","      <td>1</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>33559</td>\n","      <td>iki güzel söze yapılan hatayı unutma kerizliği...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>21134</td>\n","      <td>bunu yapan birine tl veririm</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>10906</td>\n","      <td>benden başka herkese iyi geceler</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>35942</td>\n","      <td>yakın yanlış sınırın öbür tarafı  pasaportla g...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>45435</td>\n","      <td>yıl önce hayatımın aşkını bulmuşta kaybetmiş g...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>33110</td>\n","      <td>biz suriyede abdnin kara ordusu ppkpyd ile sav...</td>\n","      <td>1</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>45877</td>\n","      <td>ben boğayım  demek oluyor ki burçlarla ilgili ...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>20138</td>\n","      <td>vatan severliğin ölçüsünü de belirtseler ona g...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>28713</td>\n","      <td>milliyetçi geçinip  mafyanın ve derin devletin...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>26882</td>\n","      <td>yöneticileri olan kulüp daha iyi nasıl yönetil...</td>\n","      <td>1</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>14668</td>\n","      <td>mhp bu ülkenin çimentosudur  bunu bilen devlet...</td>\n","      <td>1</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>26715</td>\n","      <td>gol atacak forvet yok forvet kim gol atacak be...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>15499</td>\n","      <td>okuma oranın çok düşük olduğu ve gündemi a hab...</td>\n","      <td>1</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>30936</td>\n","      <td>fedakarlık  cesaret ve inanç   o gün onlar ora...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>23667</td>\n","      <td>nasıl olsa ölünülecek ama allah son nefeste im...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>15981</td>\n","      <td>öyle bir mutlulukla izliyorum ki her konuşmanı...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>38440</td>\n","      <td>boyundayım aq ya nasıl kurayım böyle halay</td>\n","      <td>1</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>35624</td>\n","      <td>cool görüneceğim diye kanser bile olursunuz</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>13652</td>\n","      <td>çok zor  önce helallik almanız lazım</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>31257</td>\n","      <td>hepimizin psikolojisi bozuk çok azımız bunun f...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>31435</td>\n","      <td>iyi akşamlar sevgili arkadaşlar  k  maraş yaşı...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>42306</td>\n","      <td>diyorsunuz ama yaşayan ölüler mezardaki ölüler...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>29561</td>\n","      <td>size favlamakdan parmak uçlarım şişti yeminle ...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>17007</td>\n","      <td>gökyüzüne bakmayanların kalbi daha çabuk kirle...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       id                                               text  toxic lang\n","0   20948  en güzel uyuyan insan ödülü jeon jungkooka gid...      0   tr\n","1   10134  mekanı cennet olsun  saygılar sayın avukatımız...      0   tr\n","2   23457  kızlar aranızda kas yığını beylere düşenler ol...      0   tr\n","3   18401  biraz ders çalışayım  tembellik ve uyku düşman...      0   tr\n","4   17525      trezeguet yerine el sharawy daha iyi olmaz mı      0   tr\n","5   11996  bence de olması gerekiyor  hatta meslek lisesi...      0   tr\n","6   38452  mutlu görünümlü ama daima mutsuz olanlar burad...      0   tr\n","7   12615  liraya traş oldum arkadaşım diyor ki ne kesiyo...      0   tr\n","8   13520  reis bu ülkenin devlet başkanı ve ak parti gen...      1   tr\n","9   45562  var olan  ancak düşünüldüğü kadarıyla vardır  ...      0   tr\n","10  20724  şu kodumun sitesine günlerce giremeyecek kadar...      1   tr\n","11  24529   buralara değil yaz günü  kışın bile kar yağmıyor      0   tr\n","12  13853  prodüktivite arz cazibesi tolerans kolacı tomr...      0   tr\n","13  15493  muavinlerini arabı çıkar bozuk olur öyle bide ...      0   tr\n","14  13276  yalnız bunlar harabe bir yerdeler ne işleri va...      0   tr\n","15  44185  bundan sonra katiyen arkadaşlarıma dışarı çıka...      0   tr\n","16  10647  aracı ekürisinin en kötü tayı bile olsa bursa ...      0   tr\n","17  37568  bin euro ya deportivo da oynuyordu  şimdi  mil...      0   tr\n","18  15984  aşk ödü evvel düşer maşuka  andan aşıka  sami ...      0   tr\n","19  20290  bundan yıl sonrayaptıklarından çok yapmadığın ...      0   tr\n","20  46099   aşk ile ölmeden toprak olanlar canım yunus  k...      0   tr\n","21  43375  çıkış birkaç kere yapman lazım  aslında bir ta...      0   tr\n","22  44928    affetmek ve unutmak iyi insanların intikamıdır       0   tr\n","23  26789  eleştirebilirsin beğenmeyebilirsin siyasi görü...      0   tr\n","24  20741                      aşkta öyle bir şey olsa gerek      0   tr\n","25  26141     nasıl o    çocuklarıyla aynı devre denk geldik      1   tr\n","26  33559  iki güzel söze yapılan hatayı unutma kerizliği...      0   tr\n","27  21134                       bunu yapan birine tl veririm      0   tr\n","28  10906                   benden başka herkese iyi geceler      0   tr\n","29  35942  yakın yanlış sınırın öbür tarafı  pasaportla g...      0   tr\n","30  45435  yıl önce hayatımın aşkını bulmuşta kaybetmiş g...      0   tr\n","31  33110  biz suriyede abdnin kara ordusu ppkpyd ile sav...      1   tr\n","32  45877  ben boğayım  demek oluyor ki burçlarla ilgili ...      0   tr\n","33  20138  vatan severliğin ölçüsünü de belirtseler ona g...      0   tr\n","34  28713  milliyetçi geçinip  mafyanın ve derin devletin...      0   tr\n","35  26882  yöneticileri olan kulüp daha iyi nasıl yönetil...      1   tr\n","36  14668  mhp bu ülkenin çimentosudur  bunu bilen devlet...      1   tr\n","37  26715  gol atacak forvet yok forvet kim gol atacak be...      0   tr\n","38  15499  okuma oranın çok düşük olduğu ve gündemi a hab...      1   tr\n","39  30936  fedakarlık  cesaret ve inanç   o gün onlar ora...      0   tr\n","40  23667  nasıl olsa ölünülecek ama allah son nefeste im...      0   tr\n","41  15981  öyle bir mutlulukla izliyorum ki her konuşmanı...      0   tr\n","42  38440         boyundayım aq ya nasıl kurayım böyle halay      1   tr\n","43  35624        cool görüneceğim diye kanser bile olursunuz      0   tr\n","44  13652              çok zor  önce helallik almanız lazım       0   tr\n","45  31257  hepimizin psikolojisi bozuk çok azımız bunun f...      0   tr\n","46  31435  iyi akşamlar sevgili arkadaşlar  k  maraş yaşı...      0   tr\n","47  42306  diyorsunuz ama yaşayan ölüler mezardaki ölüler...      0   tr\n","48  29561  size favlamakdan parmak uçlarım şişti yeminle ...      0   tr\n","49  17007  gökyüzüne bakmayanların kalbi daha çabuk kirle...      0   tr"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"nGMtzLCiVuQT","colab_type":"code","colab":{}},"source":["tokenizer = AutoTokenizer.from_pretrained(MODEL)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8PbUt2VyKkRd","colab_type":"code","colab":{}},"source":["input_cols_external = ['text']\n","\n","external_dataset = models.DatasetRetriever(\n","    tokenizer,\n","    labels_or_ids=external['toxic'].values, \n","    comment_texts=external[input_cols_external].values, \n","    langs=external['lang'].values,\n","    maxlen=MAX_LENGTH,\n",")\n","\n","del external\n","gc.collect();"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B1cRb0P9I9RZ","colab_type":"code","colab":{}},"source":["input_cols_dev = ['comment_text']\n","\n","train_dataset = models.DatasetRetriever(\n","    tokenizer,\n","    labels_or_ids=train['toxic'].values, \n","    comment_texts=train[input_cols_dev].values, \n","    langs=train['lang'].values,\n","    open_subtitles_path=data_dir/open_subtitles_file,\n","    maxlen=MAX_LENGTH,\n","    use_train_transforms=True,\n",")\n","\n","del train\n","gc.collect();"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TqqeU_P2b08e","colab":{}},"source":["validation_tune_dataset = models.DatasetRetriever(\n","    tokenizer,\n","    labels_or_ids=valid['toxic'].values, \n","    comment_texts=valid[input_cols_dev].values, \n","    langs=valid['lang'].values,\n","    open_subtitles_path=data_dir/open_subtitles_file,\n","    maxlen=MAX_LENGTH,\n","    use_train_transforms=True,\n",")\n","\n","valid = clean.clean_data(valid, input_cols_dev)\n","\n","validation_dataset = models.DatasetRetriever(\n","    tokenizer,\n","    labels_or_ids=valid['toxic'].values, \n","    comment_texts=valid[input_cols_dev].values, \n","    langs=valid['lang'].values,\n","    maxlen=MAX_LENGTH,\n","    use_train_transforms=False,\n",")\n","\n","del valid\n","gc.collect();"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"j07T9T8uelmN","colab":{}},"source":["input_cols_test = ['content']\n","test = clean.clean_data(test, input_cols_test)\n","\n","test_dataset = models.DatasetRetriever(\n","    tokenizer,\n","    labels_or_ids=test.index.values, \n","    comment_texts=test[input_cols_test].values, \n","    langs=test['lang'].values,\n","    maxlen=MAX_LENGTH,\n","    use_train_transforms=False,\n","    test=True\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7DV-gT6vWA1T","colab_type":"code","colab":{}},"source":["transformer = AutoModel.from_pretrained(MODEL)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X5bp-Wtuw0ZI","colab_type":"code","colab":{}},"source":["net = models.ToxicSimpleNNModel(transformer)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"o6VGXhu1WVuy","colab_type":"code","outputId":"90bff4c8-568c-4472-d524-a738ac17140d","executionInfo":{"status":"ok","timestamp":1590951768314,"user_tz":-120,"elapsed":232982,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["net"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ToxicSimpleNNModel(\n","  (backbone): XLMRobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(250002, 1024, padding_idx=1)\n","      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 1024)\n","      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (12): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (13): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (14): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (15): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (16): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (17): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (18): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (19): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (20): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (21): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (22): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (23): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.3, inplace=False)\n","  (linear): Linear(in_features=2048, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"3_AcoTxMw4Bo","colab_type":"code","colab":{}},"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","def _mp_fn(rank, flags):\n","    device = xm.xla_device()\n","    net.to(device)\n","\n","    external_sampler = DistributedSamplerWrapper(\n","        sampler=BalanceClassSampler(labels=external_dataset.get_labels(), mode=\"downsampling\"),\n","        num_replicas=xm.xrt_world_size(),\n","        rank=xm.get_ordinal(),\n","        shuffle=True\n","    )\n","    external_loader = torch.utils.data.DataLoader(\n","        external_dataset,\n","        batch_size=config.TrainGlobalConfig.batch_size,\n","        sampler=external_sampler,\n","        pin_memory=False,\n","        drop_last=True,\n","        num_workers=config.TrainGlobalConfig.num_workers,\n","    )\n","\n","    train_sampler = DistributedSamplerWrapper(\n","        sampler=BalanceClassSampler(labels=train_dataset.get_labels(), mode=\"downsampling\"),\n","        num_replicas=xm.xrt_world_size(),\n","        rank=xm.get_ordinal(),\n","        shuffle=True\n","    )\n","    train_loader = torch.utils.data.DataLoader(\n","        train_dataset,\n","        batch_size=config.TrainGlobalConfig.batch_size,\n","        sampler=train_sampler,\n","        pin_memory=False,\n","        drop_last=True,\n","        num_workers=config.TrainGlobalConfig.num_workers,\n","    )\n","    validation_sampler = torch.utils.data.distributed.DistributedSampler(\n","        validation_dataset,\n","        num_replicas=xm.xrt_world_size(),\n","        rank=xm.get_ordinal(),\n","        shuffle=False\n","    )\n","    validation_loader = torch.utils.data.DataLoader(\n","        validation_dataset,\n","        batch_size=config.TrainGlobalConfig.batch_size,\n","        sampler=validation_sampler,\n","        pin_memory=False,\n","        drop_last=False,\n","        num_workers=config.TrainGlobalConfig.num_workers\n","    )\n","    validation_tune_sampler = torch.utils.data.distributed.DistributedSampler(\n","        validation_tune_dataset,\n","        num_replicas=xm.xrt_world_size(),\n","        rank=xm.get_ordinal(),\n","        shuffle=True\n","    )\n","    validation_tune_loader = torch.utils.data.DataLoader(\n","        validation_tune_dataset,\n","        batch_size=config.TrainGlobalConfig.batch_size,\n","        sampler=validation_tune_sampler,\n","        pin_memory=False,\n","        drop_last=False,\n","        num_workers=config.TrainGlobalConfig.num_workers\n","    )\n","    test_sampler = torch.utils.data.distributed.DistributedSampler(\n","        test_dataset,\n","        num_replicas=xm.xrt_world_size(),\n","        rank=xm.get_ordinal(),\n","        shuffle=False\n","    )\n","    test_loader = torch.utils.data.DataLoader(\n","        test_dataset,\n","        batch_size=config.TrainGlobalConfig.batch_size,\n","        sampler=test_sampler,\n","        pin_memory=False,\n","        drop_last=False,\n","        num_workers=config.TrainGlobalConfig.num_workers\n","    )\n","    if rank == 0:\n","        time.sleep(1)\n","    \n","    fitter = models.TPUFitter(model=net, device=device, config=config.TrainGlobalConfig, \n","                              base_model_path=model_base_dir, model_name=MODEL, model_version=MODEL_VERSION, out_path=out_dir)\n","    fitter.fit(train_loader, validation_loader)\n","    \n","    for val_epoch in range(2):\n","      fitter.run_validation_tuning(validation_tune_loader, val_epoch)\n","      # xm.master_print(f'Tuning on external data: {val_epoch}')\n","      # fitter.run_validation_tuning(external_loader, val_epoch)\n","      # fitter.run_pseudolabeling(test_loader, val_epoch)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qY4gmK7QWmkK","colab_type":"code","outputId":"01d2faee-d27f-414b-c430-b23dffdeaafc","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1590964504427,"user_tz":-120,"elapsed":12969086,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}}},"source":["FLAGS={}\n","xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')"],"execution_count":21,"outputs":[{"output_type":"stream","text":["**** Directory structure created ****\n","Fitter prepared. Device is xla:1\n","**** Fitting process has been started ****\n","\n","2020-05-31T19:04:21.086350\n","LR: 5e-06 \n","Epoch:0\n","**** Epoch training has started: 0 ****\n","Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.90838\n","Train Step 50, loss: 0.73398, final_score: 0.48565, time: 278.93813\n","Train Step 100, loss: 0.72770, final_score: 0.49984, time: 341.19105\n","Train Step 150, loss: 0.71089, final_score: 0.54342, time: 403.86972\n","Train Step 200, loss: 0.63879, final_score: 0.68616, time: 466.23505\n","Train Step 250, loss: 0.58587, final_score: 0.76689, time: 528.44172\n","Train Step 300, loss: 0.55251, final_score: 0.81204, time: 590.92672\n","Train Step 350, loss: 0.52695, final_score: 0.84225, time: 653.54522\n","Train Step 400, loss: 0.50143, final_score: 0.86747, time: 716.28493\n","Train Step 450, loss: 0.48757, final_score: 0.88160, time: 778.31325\n","Train Step 500, loss: 0.47449, final_score: 0.89300, time: 840.79354\n","Train Step 550, loss: 0.46345, final_score: 0.90207, time: 903.13077\n","Train Step 600, loss: 0.45454, final_score: 0.90930, time: 965.35991\n","Train Step 650, loss: 0.44791, final_score: 0.91443, time: 1027.56510\n","Train Step 700, loss: 0.44073, final_score: 0.91953, time: 1089.70977\n","Train Step 750, loss: 0.43465, final_score: 0.92359, time: 1151.75812\n","Train Step 800, loss: 0.42855, final_score: 0.92754, time: 1214.40792\n","Train Step 850, loss: 0.42306, final_score: 0.93100, time: 1277.15293\n","Train Step 900, loss: 0.41904, final_score: 0.93347, time: 1339.54261\n","Train Step 950, loss: 0.41444, final_score: 0.93619, time: 1402.11216\n","Train Step 1000, loss: 0.41025, final_score: 0.93857, time: 1464.23083\n","Train Step 1050, loss: 0.40588, final_score: 0.94102, time: 1527.05539\n","Train Step 1100, loss: 0.40348, final_score: 0.94229, time: 1589.51808\n","Train Step 1150, loss: 0.39949, final_score: 0.94441, time: 1651.87711\n","Train Step 1200, loss: 0.39685, final_score: 0.94578, time: 1715.01093\n","Train Step 1250, loss: 0.39440, final_score: 0.94705, time: 1777.52196\n","Train Step 1300, loss: 0.39156, final_score: 0.94848, time: 1840.74472\n","Train Step 1350, loss: 0.38968, final_score: 0.94943, time: 1903.72051\n","Train Step 1400, loss: 0.38722, final_score: 0.95068, time: 1966.93996\n","Train Step 1450, loss: 0.38455, final_score: 0.95194, time: 2030.33274\n","Train Step 1500, loss: 0.38274, final_score: 0.95281, time: 2093.21997\n","Train Step 1550, loss: 0.38105, final_score: 0.95361, time: 2155.70330\n","Train Step 1600, loss: 0.37907, final_score: 0.95450, time: 2219.05655\n","Train Step 1650, loss: 0.37654, final_score: 0.95565, time: 2281.67504\n","Train Step 1700, loss: 0.37453, final_score: 0.95656, time: 2344.83127\n","Train Step 1750, loss: 0.37286, final_score: 0.95732, time: 2408.08755\n","Train Step 1800, loss: 0.37093, final_score: 0.95816, time: 2471.11745\n","Train Step 1850, loss: 0.36973, final_score: 0.95870, time: 2534.25210\n","Train Step 1900, loss: 0.36868, final_score: 0.95917, time: 2597.21843\n","Train Step 1950, loss: 0.36701, final_score: 0.95986, time: 2660.13582\n","Train Step 2000, loss: 0.36617, final_score: 0.96021, time: 2723.31525\n","Train Step 2050, loss: 0.36481, final_score: 0.96079, time: 2785.77744\n","Train Step 2100, loss: 0.36387, final_score: 0.96109, time: 2848.79212\n","Train Step 2150, loss: 0.36273, final_score: 0.96154, time: 2911.75845\n","Train Step 2200, loss: 0.36185, final_score: 0.96191, time: 2974.95106\n","Train Step 2250, loss: 0.36075, final_score: 0.96235, time: 3038.18129\n","Train Step 2300, loss: 0.35970, final_score: 0.96282, time: 3101.79480\n","[RESULT]: Train. Epoch: 0, loss: 0.35952, final_score: 0.96287, time: 3148.34013\n","Valid Step 0, loss: 0.00000, final_score: 0.00000, time: 0.04678\n","Valid Step 50, loss: 0.45184, final_score: 0.96013, time: 59.67408\n","[RESULT]: Validation. Epoch: 0, loss: 0.46075, final_score: 0.95314, best_th: 0.500, time: 100.11384\n","\n","2020-05-31T19:58:35.355512\n","LR: 8.475250000000001e-05 \n","Epoch:1\n","**** Epoch training has started: 1 ****\n","Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.84043\n","Train Step 50, loss: 0.30297, final_score: 0.98061, time: 63.11364\n","Train Step 100, loss: 0.31142, final_score: 0.98031, time: 125.64906\n","Train Step 150, loss: 0.31178, final_score: 0.98035, time: 188.70215\n","Train Step 200, loss: 0.31032, final_score: 0.98062, time: 251.52789\n","Train Step 250, loss: 0.31063, final_score: 0.98058, time: 314.66708\n","Train Step 300, loss: 0.30864, final_score: 0.98136, time: 378.10138\n","Train Step 350, loss: 0.30820, final_score: 0.98132, time: 441.37318\n","Train Step 400, loss: 0.30801, final_score: 0.98146, time: 503.91163\n","Train Step 450, loss: 0.30671, final_score: 0.98203, time: 566.46491\n","Train Step 500, loss: 0.30749, final_score: 0.98180, time: 629.32527\n","Train Step 550, loss: 0.30708, final_score: 0.98169, time: 692.27516\n","Train Step 600, loss: 0.30533, final_score: 0.98217, time: 755.00525\n","Train Step 650, loss: 0.30463, final_score: 0.98209, time: 818.05069\n","Train Step 700, loss: 0.30273, final_score: 0.98260, time: 881.26491\n","Train Step 750, loss: 0.30402, final_score: 0.98217, time: 944.32236\n","Train Step 800, loss: 0.30365, final_score: 0.98232, time: 1006.85888\n","Train Step 850, loss: 0.30308, final_score: 0.98253, time: 1069.63371\n","Train Step 900, loss: 0.30237, final_score: 0.98278, time: 1132.41044\n","Train Step 950, loss: 0.30334, final_score: 0.98241, time: 1195.13544\n","Train Step 1000, loss: 0.30277, final_score: 0.98265, time: 1258.49383\n","Train Step 1050, loss: 0.30176, final_score: 0.98284, time: 1321.64237\n","Train Step 1100, loss: 0.30218, final_score: 0.98271, time: 1384.38311\n","Train Step 1150, loss: 0.30190, final_score: 0.98269, time: 1446.99956\n","Train Step 1200, loss: 0.30171, final_score: 0.98272, time: 1509.87642\n","Train Step 1250, loss: 0.30148, final_score: 0.98265, time: 1573.03171\n","Train Step 1300, loss: 0.30079, final_score: 0.98287, time: 1635.88116\n","Train Step 1350, loss: 0.30008, final_score: 0.98306, time: 1698.98730\n","Train Step 1400, loss: 0.30022, final_score: 0.98305, time: 1762.22896\n","Train Step 1450, loss: 0.29983, final_score: 0.98319, time: 1825.28807\n","Train Step 1500, loss: 0.29978, final_score: 0.98320, time: 1888.69512\n","Train Step 1550, loss: 0.29983, final_score: 0.98322, time: 1951.34889\n","Train Step 1600, loss: 0.29996, final_score: 0.98311, time: 2015.10529\n","Train Step 1650, loss: 0.29971, final_score: 0.98321, time: 2077.57775\n","Train Step 1700, loss: 0.29898, final_score: 0.98338, time: 2140.78912\n","Train Step 1750, loss: 0.29885, final_score: 0.98343, time: 2204.34178\n","Train Step 1800, loss: 0.29914, final_score: 0.98334, time: 2267.19869\n","Train Step 1850, loss: 0.29842, final_score: 0.98359, time: 2330.43464\n","Train Step 1900, loss: 0.29839, final_score: 0.98355, time: 2394.08793\n","Train Step 1950, loss: 0.29853, final_score: 0.98350, time: 2457.80722\n","Train Step 2000, loss: 0.29817, final_score: 0.98356, time: 2521.26067\n","Train Step 2050, loss: 0.29806, final_score: 0.98358, time: 2584.58921\n","Train Step 2100, loss: 0.29767, final_score: 0.98371, time: 2647.82389\n","Train Step 2150, loss: 0.29783, final_score: 0.98370, time: 2711.30435\n","Train Step 2200, loss: 0.29772, final_score: 0.98375, time: 2774.91251\n","Train Step 2250, loss: 0.29749, final_score: 0.98381, time: 2838.39290\n","Train Step 2300, loss: 0.29724, final_score: 0.98385, time: 2901.28422\n","[RESULT]: Train. Epoch: 1, loss: 0.29695, final_score: 0.98394, time: 2953.86073\n","Valid Step 0, loss: 0.00000, final_score: 0.00000, time: 0.05822\n","Valid Step 50, loss: 0.41428, final_score: 0.95919, time: 31.98063\n","[RESULT]: Validation. Epoch: 1, loss: 0.41943, final_score: 0.95501, best_th: 0.438, time: 39.52584\n","\n","2020-05-31T20:48:28.760221\n","LR: 2.024749999999999e-05 \n","Epoch:2\n","**** Epoch training has started: 2 ****\n","Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.82759\n","Train Step 50, loss: 0.28754, final_score: 0.98496, time: 62.85524\n","Train Step 100, loss: 0.28683, final_score: 0.98544, time: 125.89082\n","Train Step 150, loss: 0.28700, final_score: 0.98632, time: 188.75476\n","Train Step 200, loss: 0.28298, final_score: 0.98742, time: 251.76229\n","Train Step 250, loss: 0.28042, final_score: 0.98842, time: 314.47719\n","Train Step 300, loss: 0.28258, final_score: 0.98836, time: 377.24584\n","Train Step 350, loss: 0.28328, final_score: 0.98822, time: 439.92784\n","Train Step 400, loss: 0.28299, final_score: 0.98810, time: 503.29581\n","Train Step 450, loss: 0.28473, final_score: 0.98774, time: 566.05722\n","Train Step 500, loss: 0.28517, final_score: 0.98752, time: 628.82590\n","Train Step 550, loss: 0.28479, final_score: 0.98782, time: 691.27173\n","Train Step 600, loss: 0.28495, final_score: 0.98752, time: 753.88331\n","Train Step 650, loss: 0.28495, final_score: 0.98756, time: 816.80562\n","Train Step 700, loss: 0.28574, final_score: 0.98737, time: 879.82491\n","Train Step 750, loss: 0.28709, final_score: 0.98689, time: 942.74723\n","Train Step 800, loss: 0.28763, final_score: 0.98669, time: 1005.88169\n","Train Step 850, loss: 0.28740, final_score: 0.98669, time: 1068.87888\n","Train Step 900, loss: 0.28707, final_score: 0.98675, time: 1131.34774\n","Train Step 950, loss: 0.28690, final_score: 0.98675, time: 1194.43348\n","Train Step 1000, loss: 0.28707, final_score: 0.98675, time: 1257.32395\n","Train Step 1050, loss: 0.28748, final_score: 0.98660, time: 1320.02856\n","Train Step 1100, loss: 0.28724, final_score: 0.98668, time: 1382.99674\n","Train Step 1150, loss: 0.28745, final_score: 0.98652, time: 1446.31780\n","Train Step 1200, loss: 0.28795, final_score: 0.98622, time: 1509.37148\n","Train Step 1250, loss: 0.28826, final_score: 0.98617, time: 1572.59218\n","Train Step 1300, loss: 0.28812, final_score: 0.98620, time: 1635.47892\n","Train Step 1350, loss: 0.28794, final_score: 0.98622, time: 1698.69920\n","Train Step 1400, loss: 0.28764, final_score: 0.98636, time: 1762.07416\n","Train Step 1450, loss: 0.28708, final_score: 0.98650, time: 1824.84801\n","Train Step 1500, loss: 0.28760, final_score: 0.98640, time: 1887.86639\n","Train Step 1550, loss: 0.28790, final_score: 0.98635, time: 1951.14416\n","Train Step 1600, loss: 0.28816, final_score: 0.98627, time: 2014.33543\n","Train Step 1650, loss: 0.28877, final_score: 0.98606, time: 2077.42865\n","Train Step 1700, loss: 0.28817, final_score: 0.98619, time: 2140.49547\n","Train Step 1750, loss: 0.28748, final_score: 0.98640, time: 2204.14833\n","Train Step 1800, loss: 0.28776, final_score: 0.98623, time: 2267.53000\n","Train Step 1850, loss: 0.28768, final_score: 0.98629, time: 2331.29728\n","Train Step 1900, loss: 0.28804, final_score: 0.98617, time: 2394.79568\n","Train Step 1950, loss: 0.28777, final_score: 0.98621, time: 2457.72689\n","Train Step 2000, loss: 0.28777, final_score: 0.98626, time: 2520.94521\n","Train Step 2050, loss: 0.28800, final_score: 0.98621, time: 2584.44971\n","Train Step 2100, loss: 0.28800, final_score: 0.98625, time: 2647.41567\n","Train Step 2150, loss: 0.28780, final_score: 0.98631, time: 2710.95094\n","Train Step 2200, loss: 0.28780, final_score: 0.98634, time: 2774.25455\n","Train Step 2250, loss: 0.28791, final_score: 0.98632, time: 2837.37293\n","Train Step 2300, loss: 0.28807, final_score: 0.98632, time: 2901.07570\n","[RESULT]: Train. Epoch: 2, loss: 0.28792, final_score: 0.98637, time: 2952.36191\n","Valid Step 0, loss: 0.00000, final_score: 0.00000, time: 0.04571\n","Valid Step 50, loss: 0.39582, final_score: 0.95858, time: 31.37488\n","[RESULT]: Validation. Epoch: 2, loss: 0.40006, final_score: 0.95621, best_th: 0.438, time: 39.40662\n","\n","2020-05-31T21:38:20.577022\n","LR: 2.962874999999998e-05 \n","Epoch:3\n","**** Epoch training has started: 3 ****\n","Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.45651\n","Train Step 50, loss: 0.27432, final_score: 0.99103, time: 62.44168\n","Train Step 100, loss: 0.29252, final_score: 0.98579, time: 125.00494\n","Train Step 150, loss: 0.29159, final_score: 0.98610, time: 187.52878\n","Train Step 200, loss: 0.29078, final_score: 0.98540, time: 250.26886\n","Train Step 250, loss: 0.28912, final_score: 0.98560, time: 313.12498\n","Train Step 300, loss: 0.28787, final_score: 0.98545, time: 376.94272\n","Train Step 350, loss: 0.28665, final_score: 0.98566, time: 440.06657\n","Train Step 400, loss: 0.28554, final_score: 0.98613, time: 503.04178\n","Train Step 450, loss: 0.28549, final_score: 0.98622, time: 566.13201\n","Train Step 500, loss: 0.28596, final_score: 0.98613, time: 628.47713\n","Train Step 550, loss: 0.28554, final_score: 0.98643, time: 691.04225\n","Train Step 600, loss: 0.28529, final_score: 0.98669, time: 754.40348\n","Train Step 650, loss: 0.28519, final_score: 0.98661, time: 816.97246\n","Train Step 700, loss: 0.28529, final_score: 0.98652, time: 879.97294\n","Train Step 750, loss: 0.28449, final_score: 0.98668, time: 942.73017\n","Train Step 800, loss: 0.28499, final_score: 0.98636, time: 1005.48796\n","Train Step 850, loss: 0.28500, final_score: 0.98654, time: 1067.73435\n","Train Step 900, loss: 0.28489, final_score: 0.98658, time: 1130.52853\n","Train Step 950, loss: 0.28474, final_score: 0.98667, time: 1193.09272\n","Train Step 1000, loss: 0.28356, final_score: 0.98708, time: 1256.13577\n","Train Step 1050, loss: 0.28432, final_score: 0.98688, time: 1319.28899\n","Train Step 1100, loss: 0.28427, final_score: 0.98681, time: 1382.16468\n","Train Step 1150, loss: 0.28466, final_score: 0.98678, time: 1445.11767\n","Train Step 1200, loss: 0.28423, final_score: 0.98699, time: 1508.27558\n","Train Step 1250, loss: 0.28421, final_score: 0.98701, time: 1571.69032\n","Train Step 1300, loss: 0.28444, final_score: 0.98697, time: 1634.98805\n","Train Step 1350, loss: 0.28417, final_score: 0.98710, time: 1697.93039\n","Train Step 1400, loss: 0.28460, final_score: 0.98706, time: 1761.04826\n","Train Step 1450, loss: 0.28422, final_score: 0.98715, time: 1824.64794\n","Train Step 1500, loss: 0.28376, final_score: 0.98725, time: 1887.88760\n","Train Step 1550, loss: 0.28348, final_score: 0.98735, time: 1951.14146\n","Train Step 1600, loss: 0.28381, final_score: 0.98726, time: 2014.78586\n","Train Step 1650, loss: 0.28373, final_score: 0.98723, time: 2078.29626\n","Train Step 1700, loss: 0.28356, final_score: 0.98738, time: 2141.17536\n","Train Step 1750, loss: 0.28397, final_score: 0.98733, time: 2204.64708\n","Train Step 1800, loss: 0.28429, final_score: 0.98721, time: 2268.16352\n","Train Step 1850, loss: 0.28398, final_score: 0.98724, time: 2331.08980\n","Train Step 1900, loss: 0.28346, final_score: 0.98738, time: 2394.59574\n","Train Step 1950, loss: 0.28322, final_score: 0.98743, time: 2457.44809\n","Train Step 2000, loss: 0.28356, final_score: 0.98732, time: 2520.05306\n","Train Step 2050, loss: 0.28392, final_score: 0.98726, time: 2583.09219\n","Train Step 2100, loss: 0.28410, final_score: 0.98717, time: 2646.40015\n","Train Step 2150, loss: 0.28413, final_score: 0.98713, time: 2709.74276\n","Train Step 2200, loss: 0.28411, final_score: 0.98718, time: 2773.30037\n","Train Step 2250, loss: 0.28391, final_score: 0.98728, time: 2836.36123\n","Train Step 2300, loss: 0.28377, final_score: 0.98735, time: 2899.66197\n","[RESULT]: Train. Epoch: 3, loss: 0.28391, final_score: 0.98734, time: 2949.49960\n","Valid Step 0, loss: 0.00000, final_score: 0.00000, time: 0.04732\n","Valid Step 50, loss: 0.39746, final_score: 0.95734, time: 31.79723\n","[RESULT]: Validation. Epoch: 3, loss: 0.40220, final_score: 0.95481, best_th: 0.422, time: 39.68800\n","**** Epoch training has started: 0 ****\n","Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.18808\n","Train Step 50, loss: 0.33711, final_score: 0.94225, time: 148.89867\n","**** Epoch training has started: 1 ****\n","Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.10031\n","Train Step 50, loss: 0.31518, final_score: 0.95919, time: 63.73649\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IAhfU9BSod0f","colab_type":"code","colab":{}},"source":["tokenizer.save_pretrained(model_dir)\n","transformer.save_pretrained(model_dir)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yitXZLNHSlzw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"ba9fddc9-df5a-4222-b70f-337c8a27a15c","executionInfo":{"status":"ok","timestamp":1590964579884,"user_tz":-120,"elapsed":13044535,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}}},"source":["config_path = (model_dir/\"config.json\")\n","model_metadata = {'model_name': MODEL, \"model_version\": MODEL_VERSION, \"max_len\": MAX_LENGTH}\n","\n","with open(config_path) as f:\n","    data = json.load(f)\n","\n","data.update(model_metadata)\n","\n","with open(config_path, 'w') as f:\n","    json.dump(data, f, indent=3, sort_keys=True)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["{'architectures': ['XLMRobertaModel'], 'attention_probs_dropout_prob': 0.1, 'bos_token_id': 0, 'do_sample': False, 'eos_token_id': 2, 'eos_token_ids': None, 'finetuning_task': None, 'hidden_act': 'gelu', 'hidden_dropout_prob': 0.1, 'hidden_size': 1024, 'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'}, 'initializer_range': 0.02, 'intermediate_size': 4096, 'is_decoder': False, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'layer_norm_eps': 1e-05, 'length_penalty': 1.0, 'max_length': 20, 'max_position_embeddings': 514, 'model_type': 'xlm-roberta', 'num_attention_heads': 16, 'num_beams': 1, 'num_hidden_layers': 24, 'num_labels': 2, 'num_return_sequences': 1, 'output_attentions': False, 'output_hidden_states': False, 'output_past': True, 'pad_token_id': 1, 'pruned_heads': {}, 'repetition_penalty': 1.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'torchscript': False, 'type_vocab_size': 1, 'use_bfloat16': False, 'vocab_size': 250002, 'model_name': 'xlm-roberta-large', 'model_version': 'v1', 'max_len': 224}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fblcKnLPIRnT","colab_type":"code","colab":{}},"source":["with open(Path(root_dir, \"credentials/kaggle.json\")) as cred_json:\n","    creds = json.load(cred_json)\n","\n","os.environ[\"KAGGLE_USERNAME\"] = creds['username']\n","os.environ[\"KAGGLE_KEY\"] = creds['key']\n","\n","from kaggle.api.kaggle_api_extended import KaggleApi\n","new_model = {\n","  \"title\": f\"{MODEL}\", \n","  \"description\": \"Trained model for toxic comment challange\",\n","  \"id\": f\"quanncore/{MODEL.lower()}\", \n","  \"licenses\": [{\"name\": \"CC0-1.0\"}],\n","  \"resources\": [\n","    {\n","      \"path\": \"last-checkpoint.bin\",\n","      \"description\": \"Saved model file\"\n","    },\n","    {\n","      \"path\": \"sentencepiece.bpe.model\",\n","      \"description\": \"sentencepiece model\"\n","    },\n","    {\n","      \"path\": \"special_tokens_map.json\",\n","      \"description\": \"Special token map\"\n","    },\n","    {\n","      \"path\": \"log.txt\",\n","      \"description\": \"Log file of trained model\"\n","    },\n","    {\n","      \"path\": \"tokenizer_config.json\",\n","      \"description\": \"Tokenizer config\"\n","    },\n","    {\n","      \"path\": \"config.json\",\n","      \"description\": \"Model config\"\n","    }\n","  ],\n","}\n","\n","def update_model_kaggle():\n","  api = KaggleApi()\n","  api.authenticate()\n","\n","  dataset_id = f\"quanncore/{MODEL.lower()}\"\n","  with open((model_dir/'dataset-metadata.json'), 'w') as fp:\n","    json.dump(new_model, fp)\n","  \n","  response = api.dataset_status(dataset_id)\n","  if response == None:\n","    print('Creating a new dataset\\n')\n","    api.dataset_create_new(model_dir)\n","  else:\n","    print(f'Got response: {response}\\n. Creating a new version\\n')\n","    api.dataset_create_version(model_dir, version_notes=f'new version: {MODEL_VERSION.lower()}')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xkCL1xJS0aZV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":434},"outputId":"03cf8615-43c8-40ae-e5ff-1e4b8b0d0511","executionInfo":{"status":"ok","timestamp":1590964658979,"user_tz":-120,"elapsed":13123619,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}}},"source":["update_model_kaggle()"],"execution_count":25,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0.00/39.8k [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Got response: ready\n",". Creating a new version\n","\n","Starting upload for file log.txt\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 39.8k/39.8k [00:01<00:00, 35.0kB/s]\n","  0%|          | 0.00/150 [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: log.txt (40KB)\n","Starting upload for file special_tokens_map.json\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 150/150 [00:01<00:00, 139B/s]\n","  0%|          | 0.00/16.0 [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: special_tokens_map.json (150B)\n","Starting upload for file tokenizer_config.json\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 16.0/16.0 [00:00<00:00, 18.9B/s]\n","  0%|          | 0.00/1.15k [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: tokenizer_config.json (16B)\n","Starting upload for file config.json\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.15k/1.15k [00:00<00:00, 1.23kB/s]\n","  0%|          | 0.00/4.83M [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: config.json (1KB)\n","Starting upload for file sentencepiece.bpe.model\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 4.83M/4.83M [00:00<00:00, 5.91MB/s]\n","  0%|          | 0.00/2.09G [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: sentencepiece.bpe.model (5MB)\n","Starting upload for file pytorch_model.bin\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 2.09G/2.09G [00:37<00:00, 59.8MB/s]\n","  0%|          | 0.00/2.09G [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: pytorch_model.bin (2GB)\n","Starting upload for file last-checkpoint.bin\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 2.09G/2.09G [00:32<00:00, 68.8MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: last-checkpoint.bin (2GB)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zdKvaU4Mqi92","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":914},"outputId":"07605772-2699-4203-bbd8-592a274baf06","executionInfo":{"status":"error","timestamp":1591014022038,"user_tz":-120,"elapsed":589,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}}},"source":["%cd \"{root_dir}\"\n","!git status"],"execution_count":16,"outputs":[{"output_type":"stream","text":["ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-16-1f5d9924db09>\", line 1, in <module>\n","    get_ipython().magic('cd \"{root_dir}\"')\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2160, in magic\n","    return self.run_line_magic(magic_name, magic_arg_s)\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2081, in run_line_magic\n","    result = fn(*args,**kwargs)\n","  File \"<decorator-gen-91>\", line 2, in cd\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\", line 188, in <lambda>\n","    call = lambda f, *a, **k: f(*a, **k)\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/magics/osm.py\", line 288, in cd\n","    oldcwd = py3compat.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'OSError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n","    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n","  File \"/usr/lib/python3.6/inspect.py\", line 725, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.6/inspect.py\", line 709, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.6/posixpath.py\", line 383, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n"],"name":"stdout"},{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"]}]},{"cell_type":"code","metadata":{"id":"wX5tE4yiqpE3","colab_type":"code","colab":{}},"source":["!git add ."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5WrWqutYqrwt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":364},"outputId":"962b0c15-ed35-489f-d661-61b7e34d8b64","executionInfo":{"status":"ok","timestamp":1591013761720,"user_tz":-120,"elapsed":8383,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}}},"source":["# todo: please fill the lb score after making submission\n","git_comment = f'Model: {MODEL} Version: {MODEL_VERSION} Kaggle LB Score: {0.9301}'\n","!git commit -m \"{git_comment}\"\n","!git config --global user.email \"{GIT_EMAIL}\"\n","!git config --global user.name \"{GIT_USERNAME}\"\n","!git push origin master"],"execution_count":14,"outputs":[{"output_type":"stream","text":["[master 5164ccb] Model: xlm-roberta-large Version: v1 Kaggle LB Score: 0.9301\n"," 11 files changed, 1813 insertions(+), 1527 deletions(-)\n"," create mode 100644 .gitignore\n"," delete mode 100644 README.md\n"," create mode 100644 notebooks/pytorch_model.ipynb\n"," delete mode 100644 pytorch_model.ipynb\n"," create mode 100644 scripts/__init__.py\n"," create mode 100644 scripts/albumentation.py\n"," create mode 100644 scripts/config.py\n"," create mode 100644 scripts/data_cleaning.py\n"," create mode 100644 scripts/metrics_loss.py\n"," create mode 100644 scripts/models.py\n"," create mode 100644 scripts/utility.py\n","Counting objects: 13, done.\n","Delta compression using up to 40 threads.\n","Compressing objects: 100% (10/10), done.\n","Writing objects: 100% (13/13), 43.04 KiB | 2.69 MiB/s, done.\n","Total 13 (delta 0), reused 0 (delta 0)\n","To https://github.com/quancore/toxic-comment.git\n","   23320ba..5164ccb  master -> master\n"],"name":"stdout"}]}]}