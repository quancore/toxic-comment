{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pytorch_model.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyN1w7hQ7wBquXKPd9jsq/jj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"sPJVqAKyml5W","colab_type":"code","cellView":"both","colab":{"base_uri":"https://localhost:8080/","height":990},"executionInfo":{"status":"ok","timestamp":1592945169897,"user_tz":-120,"elapsed":70954,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}},"outputId":"4faf4105-3555-4fc1-c67a-eef7646417be"},"source":["VERSION = \"20200515\"  #@param [\"1.5\" , \"20200515\", \"nightly\"]\n","!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n","!python pytorch-xla-env-setup.py --version $VERSION"],"execution_count":2,"outputs":[{"output_type":"stream","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  4264  100  4264    0     0  24790      0 --:--:-- --:--:-- --:--:-- 24790\n","Updating TPU and VM. This may take around 2 minutes.\n","Updating TPU runtime to pytorch-dev20200515 ...\n","Uninstalling torch-1.5.1+cu101:\n","Done updating TPU runtime: <Response [200]>\n","  Successfully uninstalled torch-1.5.1+cu101\n","Uninstalling torchvision-0.6.1+cu101:\n","  Successfully uninstalled torchvision-0.6.1+cu101\n","Copying gs://tpu-pytorch/wheels/torch-nightly+20200515-cp36-cp36m-linux_x86_64.whl...\n","\\ [1 files][ 91.0 MiB/ 91.0 MiB]                                                \n","Operation completed over 1 objects/91.0 MiB.                                     \n","Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200515-cp36-cp36m-linux_x86_64.whl...\n","\\ [1 files][119.5 MiB/119.5 MiB]                                                \n","Operation completed over 1 objects/119.5 MiB.                                    \n","Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200515-cp36-cp36m-linux_x86_64.whl...\n","/ [1 files][  2.3 MiB/  2.3 MiB]                                                \n","Operation completed over 1 objects/2.3 MiB.                                      \n","Processing ./torch-nightly+20200515-cp36-cp36m-linux_x86_64.whl\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200515) (0.16.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200515) (1.18.5)\n","\u001b[31mERROR: fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\n","Installing collected packages: torch\n","Successfully installed torch-1.6.0a0+bf2bbd9\n","Processing ./torch_xla-nightly+20200515-cp36-cp36m-linux_x86_64.whl\n","Installing collected packages: torch-xla\n","Successfully installed torch-xla-1.6+2b2085a\n","Processing ./torchvision-nightly+20200515-cp36-cp36m-linux_x86_64.whl\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200515) (1.6.0a0+bf2bbd9)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200515) (7.0.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200515) (1.18.5)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==nightly+20200515) (0.16.0)\n","Installing collected packages: torchvision\n","Successfully installed torchvision-0.7.0a0+a6073f0\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-440\n","Use 'apt autoremove' to remove it.\n","The following NEW packages will be installed:\n","  libomp5\n","0 upgraded, 1 newly installed, 0 to remove and 59 not upgraded.\n","Need to get 234 kB of archives.\n","After this operation, 774 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n","Fetched 234 kB in 1s (375 kB/s)\n","Selecting previously unselected package libomp5:amd64.\n","(Reading database ... 144328 files and directories currently installed.)\n","Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n","Unpacking libomp5:amd64 (5.0.1-1) ...\n","Setting up libomp5:amd64 (5.0.1-1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HsZb7QICuRIe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":746},"executionInfo":{"status":"ok","timestamp":1592945206587,"user_tz":-120,"elapsed":104507,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}},"outputId":"5dbff732-4579-4f7a-98cb-27e989f42be2"},"source":["!pip install --upgrade git+https://github.com/pytorch/contrib.git > /dev/null\n","!pip install transformers==2.5.1 > /dev/null\n","!pip install pandarallel > /dev/null\n","!pip install catalyst==20.4.2 > /dev/null\n","!pip install kaggle\n","!pip install emoji\n","!pip install num2words\n","# !pip install -U git+https://github.com/aboSamoor/polyglot.git@master\n","!pip install --upgrade language_tool_python\n","!pip install --upgrade turkishnlp"],"execution_count":3,"outputs":[{"output_type":"stream","text":["  Running command git clone -q https://github.com/pytorch/contrib.git /tmp/pip-req-build-qv7exn4o\n","Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.4.5.2)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n","Collecting emoji\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/8d/521be7f0091fe0f2ae690cc044faf43e3445e0ff33c574eae752dd7e39fa/emoji-0.5.4.tar.gz (43kB)\n","\u001b[K     |████████████████████████████████| 51kB 2.0MB/s \n","\u001b[?25hBuilding wheels for collected packages: emoji\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-0.5.4-cp36-none-any.whl size=42176 sha256=87a761ed25d528313683687526854bcfcf0052596fcc93c6376daddc675abecc\n","  Stored in directory: /root/.cache/pip/wheels/2a/a9/0a/4f8e8cce8074232aba240caca3fade315bb49fac68808d1a9c\n","Successfully built emoji\n","Installing collected packages: emoji\n","Successfully installed emoji-0.5.4\n","Collecting num2words\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/a2/ea800689730732e27711c41beed4b2a129b34974435bdc450377ec407738/num2words-0.5.10-py3-none-any.whl (101kB)\n","\u001b[K     |████████████████████████████████| 102kB 776kB/s \n","\u001b[?25hRequirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.6/dist-packages (from num2words) (0.6.2)\n","Installing collected packages: num2words\n","Successfully installed num2words-0.5.10\n","Collecting language_tool_python\n","  Downloading https://files.pythonhosted.org/packages/e5/6e/abbf7898f28ad53c224052b5b781246631d6629b0b88f71095007b3008b6/language_tool_python-2.2.3-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from language_tool_python) (4.41.1)\n","Installing collected packages: language-tool-python\n","Successfully installed language-tool-python-2.2.3\n","Collecting turkishnlp\n","  Downloading https://files.pythonhosted.org/packages/9d/05/84e26ea98e5818ba430d6905c4640a526f7a3e59a64d010c42e80a889890/turkishnlp-0.0.61.tar.gz\n","Building wheels for collected packages: turkishnlp\n","  Building wheel for turkishnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for turkishnlp: filename=turkishnlp-0.0.61-cp36-none-any.whl size=7557 sha256=24ecc1df326133b3c2ac47df5436811376dbbb47ead53c53d18c403dc4932b23\n","  Stored in directory: /root/.cache/pip/wheels/06/11/95/9c04635b9b6cb20e8036e26a6cadaa86b32521a85155b6f1ca\n","Successfully built turkishnlp\n","Installing collected packages: turkishnlp\n","Successfully installed turkishnlp-0.0.61\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lfxkXZQf1nLt","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592652732576,"user_tz":-120,"elapsed":73865,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}}},"source":["# arr=[]\n","# while(1):\n","#  arr.append(1)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"IIWDJmzxhtM9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":228},"executionInfo":{"status":"ok","timestamp":1592945948126,"user_tz":-120,"elapsed":843781,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}},"outputId":"535aae79-1089-4839-c9dc-ffe13758b741"},"source":["%load_ext autoreload\n","%autoreload 2 \n","\n","from google.colab import drive\n","\n","drive.mount(\"/content/drive\", force_remount=True)\n","\n","import sys\n","sys.path.append('drive/My Drive/toxic_comment/scripts')\n","\n","import os\n","os.environ['XLA_USE_BF16'] = \"1\"\n","\n","import gc\n","import time\n","import json\n","import random\n","from pathlib import Path\n","from importlib import reload\n","\n","import utility as utils\n","import albumentations as alb\n","import data_cleaning as clean\n","import models\n","import config\n","\n","reload(utils)\n","reload(alb)\n","reload(clean)\n","reload(models)\n","reload(config)\n","\n","\n","import numpy as np\n","import pandas as pd\n","from transformers import AutoModel, AutoTokenizer, AutoConfig\n","from tqdm import tqdm\n","tqdm.pandas()\n","\n","from pandarallel import pandarallel\n","\n","import torch\n","from torch.utils.data import DataLoader\n","import torch_xla.core.xla_model as xm\n","import torch_xla.distributed.xla_multiprocessing as xmp\n","from catalyst.data.sampler import DistributedSamplerWrapper, BalanceClassSampler\n","\n","pandarallel.initialize(nb_workers=16, progress_bar=False)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","INFO: Pandarallel will run on 16 workers.\n","INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J9iEdfKAzU0q","colab_type":"code","colab":{}},"source":["root_dir = \"drive/My Drive/toxic_comment\"\n","\n","# *Git related variables\n","\n","\n","GIT_REPOSITORY = \"toxic-comment\" \n","GIT_CREDENTIALS = Path(root_dir, \"credentials/git_creds.json\")\n","\n","def git_path():\n","  with open(GIT_CREDENTIALS) as cred_json:\n","    creds = json.load(cred_json)\n","\n","  GIT_PATH = \"https://\" + creds['token'] + \"@github.com/\" + creds['username'] + \"/\" + GIT_REPOSITORY + \".git\"\n","  print(f'GIT_PATH: {GIT_PATH}')\n","\n","  return GIT_PATH, creds['email'], creds['username']\n","\n","GIT_PATH, GIT_EMAIL, GIT_USERNAME = git_path()\n","\n","\n","# *Model related variables\n","SEED = 42\n","MODEL = 'xlm-roberta-large'\n","# the prefix used for identifiying pretrained language model layers\n","# in order to tune with different learning rate\n","MODEL_PREFIX = 'roberta'\n","MODEL_VERSION = 'v2'\n","MAX_LENGTH = 224\n","\n","LANGS = {\n","    'en': 'english',\n","    'it': 'italian', \n","    'fr': 'french', \n","    'es': 'spanish',\n","    'tr': 'turkish', \n","    'ru': 'russian',\n","    'pt': 'portuguese'\n","}\n","\n","# *Data access\n","data_dir = Path(root_dir, \"data\")\n","data_t_dir = data_dir/\"jigsaw-toxic/translations\"\n","\n","# *Model paths\n","model_base_dir = Path(root_dir, \"models\")\n","model_dir = (model_base_dir/MODEL/MODEL_VERSION)\n","\n","# *Files\n","train_file1 = \"jigsaw-toxic/jigsaw-toxic-comment-train.csv\"\n","train_file2 = \"jigsaw-toxic/jigsaw-unintended-bias-train.csv\"\n","val_file = \"jigsaw-toxic/validation.csv\"\n","val_file_translated1 = \"jigsaw-toxic-comment-valid-yandex-en.csv\"\n","val_file_translated2 = \"jigsaw-toxic-comment-valid-google-en.csv\"\n","test_file = \"jigsaw-toxic/test.csv\"\n","test_file_translated1 = \"jigsaw-toxic-comment-test-yandex-en.csv\"\n","test_file_translated2 = \"jigsaw-toxic-comment-test-google-en.csv\"\n","sub_file = \"jigsaw-toxic/sample_submission.csv\"\n","open_subtitles_file = 'open-subtitles-toxic/open-subtitles-synthesic.csv'\n","\n","out_dir = Path(root_dir, 'output')\n","\n","# this varibale indicates whether we are using fully english data pipeline\n","# in this pipeline, we are using english trasnlated validation test data\n","english_pipeline=False\n","\n","# this parameter controls whether we are using multisample dropout or not for our NN model\n","output_hidden_states=True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mPuE1HQMhVNU","colab_type":"code","colab":{}},"source":["!git clone \"{GIT_PATH}\" ./temp      # clone github repository to temp folder\n","!mv ./temp/.git \"{root_dir}/.git\"       # move all files/folders in temp folder to folder defined in project path\n","!rm -rf ./temp                      # remove all the files/folders in temp folder"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"im4lCmzD1dx_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592652741063,"user_tz":-120,"elapsed":82327,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}}},"source":["def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","    # xm.set_rng_state(seed) # new line\n","\n","seed_everything(SEED)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"O-hcJSL1hxdC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"status":"ok","timestamp":1592652810472,"user_tz":-120,"elapsed":151731,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}},"outputId":"f6a3e074-8281-4aaa-b98f-e24bc9ea6feb"},"source":["%%time\n","# Read the data and external sources\n","dir_paths = {'base_dir': data_dir, 'base_t_dir': data_t_dir, 'train_file1': train_file1, 'train_file2': train_file2, \n","             'val_file': val_file, 'val_file_translated1': val_file_translated1, 'val_file_translated2': val_file_translated2,\n","             'test_file': test_file, 'test_file_translated1': test_file_translated1, 'test_file_translated2': test_file_translated2,\n","             'sub_file': sub_file}\n","train, valid, test, sub = utils.read_data(dir_paths, list(LANGS.keys()), english_pipeline=english_pipeline)\n","external = utils.read_external_data((data_dir/'external'), list(LANGS.values()))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Translation has not found: drive/My Drive/toxic_comment/data/jigsaw-toxic/translations/jigsaw-toxic-comment-train-google-en-cleaned.csv\n","File not found: drive/My Drive/toxic_comment/data/external/english-external-cleaned.csv\n","File not found: drive/My Drive/toxic_comment/data/external/italian-external-cleaned.csv\n","File not found: drive/My Drive/toxic_comment/data/external/french-external-cleaned.csv\n","File not found: drive/My Drive/toxic_comment/data/external/spanish-external-cleaned.csv\n","File not found: drive/My Drive/toxic_comment/data/external/russian-external-cleaned.csv\n","File not found: drive/My Drive/toxic_comment/data/external/portuguese-external-cleaned.csv\n","CPU times: user 47.4 s, sys: 4.6 s, total: 52 s\n","Wall time: 1min 9s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_yoQXP4YPcmP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":276},"executionInfo":{"status":"ok","timestamp":1592652811715,"user_tz":-120,"elapsed":152966,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}},"outputId":"f0b0554d-9199-4066-a55f-82e90d0b92f5"},"source":["train['lang'].hist(bins=20);"],"execution_count":9,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"H4p0Mp8qMxGo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592652812438,"user_tz":-120,"elapsed":153681,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}},"outputId":"d23319e1-4c5c-49fe-b510-1b16d66706f9"},"source":["train['comment_text'].isna().sum()"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"-Uoz_VGI1Tmh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":455},"executionInfo":{"status":"ok","timestamp":1592652812442,"user_tz":-120,"elapsed":153678,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}},"outputId":"e06cbba9-b474-4518-a5c9-642a0c414f37"},"source":["valid"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>comment_text</th>\n","      <th>lang</th>\n","      <th>toxic</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Este usuario ni siquiera llega al rango de    ...</td>\n","      <td>es</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Il testo di questa voce pare esser scopiazzato...</td>\n","      <td>it</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Vale. Sólo expongo mi pasado. Todo tiempo pasa...</td>\n","      <td>es</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Bu maddenin alt başlığı olarak  uluslararası i...</td>\n","      <td>tr</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Belçika nın şehirlerinin yanında ilçe ve belde...</td>\n","      <td>tr</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7995</th>\n","      <td>Il fatto è che la pagina dei personaggi minor...</td>\n","      <td>it</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7996</th>\n","      <td>El imbesil ete dela luna no se entera ni ostia...</td>\n","      <td>es</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7997</th>\n","      <td>olum sız manyakmısınz siz adam sıze sanal yıld...</td>\n","      <td>tr</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7998</th>\n","      <td>El mapa del reinado de Alhaken esta ligerament...</td>\n","      <td>es</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7999</th>\n","      <td>lasciami la tua email per favore. ad ogni modo...</td>\n","      <td>it</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8000 rows × 3 columns</p>\n","</div>"],"text/plain":["                                           comment_text lang  toxic\n","id                                                                 \n","0     Este usuario ni siquiera llega al rango de    ...   es      0\n","1     Il testo di questa voce pare esser scopiazzato...   it      0\n","2     Vale. Sólo expongo mi pasado. Todo tiempo pasa...   es      1\n","3     Bu maddenin alt başlığı olarak  uluslararası i...   tr      0\n","4     Belçika nın şehirlerinin yanında ilçe ve belde...   tr      0\n","...                                                 ...  ...    ...\n","7995   Il fatto è che la pagina dei personaggi minor...   it      0\n","7996  El imbesil ete dela luna no se entera ni ostia...   es      1\n","7997  olum sız manyakmısınz siz adam sıze sanal yıld...   tr      1\n","7998  El mapa del reinado de Alhaken esta ligerament...   es      0\n","7999  lasciami la tua email per favore. ad ogni modo...   it      0\n","\n","[8000 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"VErT41jaH8h6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592652812444,"user_tz":-120,"elapsed":153673,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}},"outputId":"923c8fa6-dca9-48cd-dc64-4dbab449da35"},"source":["external.head(50)"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","      <th>toxic</th>\n","      <th>lang</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>20948</td>\n","      <td>en güzel uyuyan insan ödülü jeon jungkooka gid...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10134</td>\n","      <td>mekanı cennet olsun  saygılar sayın avukatımız...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>23457</td>\n","      <td>kızlar aranızda kas yığını beylere düşenler ol...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>18401</td>\n","      <td>biraz ders çalışayım  tembellik ve uyku düşman...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>17525</td>\n","      <td>trezeguet yerine el sharawy daha iyi olmaz mı</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>11996</td>\n","      <td>bence de olması gerekiyor  hatta meslek lisesi...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>38452</td>\n","      <td>mutlu görünümlü ama daima mutsuz olanlar burad...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>12615</td>\n","      <td>liraya traş oldum arkadaşım diyor ki ne kesiyo...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>13520</td>\n","      <td>reis bu ülkenin devlet başkanı ve ak parti gen...</td>\n","      <td>1</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>45562</td>\n","      <td>var olan  ancak düşünüldüğü kadarıyla vardır  ...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>20724</td>\n","      <td>şu kodumun sitesine günlerce giremeyecek kadar...</td>\n","      <td>1</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>24529</td>\n","      <td>buralara değil yaz günü  kışın bile kar yağmıyor</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>13853</td>\n","      <td>prodüktivite arz cazibesi tolerans kolacı tomr...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>15493</td>\n","      <td>muavinlerini arabı çıkar bozuk olur öyle bide ...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>13276</td>\n","      <td>yalnız bunlar harabe bir yerdeler ne işleri va...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>44185</td>\n","      <td>bundan sonra katiyen arkadaşlarıma dışarı çıka...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>10647</td>\n","      <td>aracı ekürisinin en kötü tayı bile olsa bursa ...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>37568</td>\n","      <td>bin euro ya deportivo da oynuyordu  şimdi  mil...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>15984</td>\n","      <td>aşk ödü evvel düşer maşuka  andan aşıka  sami ...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>20290</td>\n","      <td>bundan yıl sonrayaptıklarından çok yapmadığın ...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>46099</td>\n","      <td>aşk ile ölmeden toprak olanlar canım yunus  k...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>43375</td>\n","      <td>çıkış birkaç kere yapman lazım  aslında bir ta...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>44928</td>\n","      <td>affetmek ve unutmak iyi insanların intikamıdır</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>26789</td>\n","      <td>eleştirebilirsin beğenmeyebilirsin siyasi görü...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>20741</td>\n","      <td>aşkta öyle bir şey olsa gerek</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>26141</td>\n","      <td>nasıl o    çocuklarıyla aynı devre denk geldik</td>\n","      <td>1</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>33559</td>\n","      <td>iki güzel söze yapılan hatayı unutma kerizliği...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>21134</td>\n","      <td>bunu yapan birine tl veririm</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>10906</td>\n","      <td>benden başka herkese iyi geceler</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>35942</td>\n","      <td>yakın yanlış sınırın öbür tarafı  pasaportla g...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>45435</td>\n","      <td>yıl önce hayatımın aşkını bulmuşta kaybetmiş g...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>33110</td>\n","      <td>biz suriyede abdnin kara ordusu ppkpyd ile sav...</td>\n","      <td>1</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>45877</td>\n","      <td>ben boğayım  demek oluyor ki burçlarla ilgili ...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>20138</td>\n","      <td>vatan severliğin ölçüsünü de belirtseler ona g...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>28713</td>\n","      <td>milliyetçi geçinip  mafyanın ve derin devletin...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>26882</td>\n","      <td>yöneticileri olan kulüp daha iyi nasıl yönetil...</td>\n","      <td>1</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>14668</td>\n","      <td>mhp bu ülkenin çimentosudur  bunu bilen devlet...</td>\n","      <td>1</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>26715</td>\n","      <td>gol atacak forvet yok forvet kim gol atacak be...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>15499</td>\n","      <td>okuma oranın çok düşük olduğu ve gündemi a hab...</td>\n","      <td>1</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>30936</td>\n","      <td>fedakarlık  cesaret ve inanç   o gün onlar ora...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>23667</td>\n","      <td>nasıl olsa ölünülecek ama allah son nefeste im...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>15981</td>\n","      <td>öyle bir mutlulukla izliyorum ki her konuşmanı...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>38440</td>\n","      <td>boyundayım aq ya nasıl kurayım böyle halay</td>\n","      <td>1</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>35624</td>\n","      <td>cool görüneceğim diye kanser bile olursunuz</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>13652</td>\n","      <td>çok zor  önce helallik almanız lazım</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>31257</td>\n","      <td>hepimizin psikolojisi bozuk çok azımız bunun f...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>31435</td>\n","      <td>iyi akşamlar sevgili arkadaşlar  k  maraş yaşı...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>42306</td>\n","      <td>diyorsunuz ama yaşayan ölüler mezardaki ölüler...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>29561</td>\n","      <td>size favlamakdan parmak uçlarım şişti yeminle ...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>17007</td>\n","      <td>gökyüzüne bakmayanların kalbi daha çabuk kirle...</td>\n","      <td>0</td>\n","      <td>tr</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       id                                               text  toxic lang\n","0   20948  en güzel uyuyan insan ödülü jeon jungkooka gid...      0   tr\n","1   10134  mekanı cennet olsun  saygılar sayın avukatımız...      0   tr\n","2   23457  kızlar aranızda kas yığını beylere düşenler ol...      0   tr\n","3   18401  biraz ders çalışayım  tembellik ve uyku düşman...      0   tr\n","4   17525      trezeguet yerine el sharawy daha iyi olmaz mı      0   tr\n","5   11996  bence de olması gerekiyor  hatta meslek lisesi...      0   tr\n","6   38452  mutlu görünümlü ama daima mutsuz olanlar burad...      0   tr\n","7   12615  liraya traş oldum arkadaşım diyor ki ne kesiyo...      0   tr\n","8   13520  reis bu ülkenin devlet başkanı ve ak parti gen...      1   tr\n","9   45562  var olan  ancak düşünüldüğü kadarıyla vardır  ...      0   tr\n","10  20724  şu kodumun sitesine günlerce giremeyecek kadar...      1   tr\n","11  24529   buralara değil yaz günü  kışın bile kar yağmıyor      0   tr\n","12  13853  prodüktivite arz cazibesi tolerans kolacı tomr...      0   tr\n","13  15493  muavinlerini arabı çıkar bozuk olur öyle bide ...      0   tr\n","14  13276  yalnız bunlar harabe bir yerdeler ne işleri va...      0   tr\n","15  44185  bundan sonra katiyen arkadaşlarıma dışarı çıka...      0   tr\n","16  10647  aracı ekürisinin en kötü tayı bile olsa bursa ...      0   tr\n","17  37568  bin euro ya deportivo da oynuyordu  şimdi  mil...      0   tr\n","18  15984  aşk ödü evvel düşer maşuka  andan aşıka  sami ...      0   tr\n","19  20290  bundan yıl sonrayaptıklarından çok yapmadığın ...      0   tr\n","20  46099   aşk ile ölmeden toprak olanlar canım yunus  k...      0   tr\n","21  43375  çıkış birkaç kere yapman lazım  aslında bir ta...      0   tr\n","22  44928    affetmek ve unutmak iyi insanların intikamıdır       0   tr\n","23  26789  eleştirebilirsin beğenmeyebilirsin siyasi görü...      0   tr\n","24  20741                      aşkta öyle bir şey olsa gerek      0   tr\n","25  26141     nasıl o    çocuklarıyla aynı devre denk geldik      1   tr\n","26  33559  iki güzel söze yapılan hatayı unutma kerizliği...      0   tr\n","27  21134                       bunu yapan birine tl veririm      0   tr\n","28  10906                   benden başka herkese iyi geceler      0   tr\n","29  35942  yakın yanlış sınırın öbür tarafı  pasaportla g...      0   tr\n","30  45435  yıl önce hayatımın aşkını bulmuşta kaybetmiş g...      0   tr\n","31  33110  biz suriyede abdnin kara ordusu ppkpyd ile sav...      1   tr\n","32  45877  ben boğayım  demek oluyor ki burçlarla ilgili ...      0   tr\n","33  20138  vatan severliğin ölçüsünü de belirtseler ona g...      0   tr\n","34  28713  milliyetçi geçinip  mafyanın ve derin devletin...      0   tr\n","35  26882  yöneticileri olan kulüp daha iyi nasıl yönetil...      1   tr\n","36  14668  mhp bu ülkenin çimentosudur  bunu bilen devlet...      1   tr\n","37  26715  gol atacak forvet yok forvet kim gol atacak be...      0   tr\n","38  15499  okuma oranın çok düşük olduğu ve gündemi a hab...      1   tr\n","39  30936  fedakarlık  cesaret ve inanç   o gün onlar ora...      0   tr\n","40  23667  nasıl olsa ölünülecek ama allah son nefeste im...      0   tr\n","41  15981  öyle bir mutlulukla izliyorum ki her konuşmanı...      0   tr\n","42  38440         boyundayım aq ya nasıl kurayım böyle halay      1   tr\n","43  35624        cool görüneceğim diye kanser bile olursunuz      0   tr\n","44  13652              çok zor  önce helallik almanız lazım       0   tr\n","45  31257  hepimizin psikolojisi bozuk çok azımız bunun f...      0   tr\n","46  31435  iyi akşamlar sevgili arkadaşlar  k  maraş yaşı...      0   tr\n","47  42306  diyorsunuz ama yaşayan ölüler mezardaki ölüler...      0   tr\n","48  29561  size favlamakdan parmak uçlarım şişti yeminle ...      0   tr\n","49  17007  gökyüzüne bakmayanların kalbi daha çabuk kirle...      0   tr"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"nGMtzLCiVuQT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592652813760,"user_tz":-120,"elapsed":154981,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}}},"source":["tokenizer = AutoTokenizer.from_pretrained(MODEL)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"8PbUt2VyKkRd","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592652813765,"user_tz":-120,"elapsed":154980,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}}},"source":["input_cols_external = ['text']\n","\n","external_dataset = models.DatasetRetriever(\n","    tokenizer,\n","    labels_or_ids=external['toxic'].values, \n","    comment_texts=external[input_cols_external].values, \n","    langs=external['lang'].values,\n","    maxlen=MAX_LENGTH,\n",")\n","\n","del external\n","gc.collect();"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"RczY2VJKrYew","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":878},"executionInfo":{"status":"ok","timestamp":1592652814094,"user_tz":-120,"elapsed":155304,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}},"outputId":"8167eae2-02d1-48b4-fc12-328031ddaf67"},"source":["train"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>comment_text</th>\n","      <th>toxic</th>\n","      <th>severe_toxic</th>\n","      <th>obscene</th>\n","      <th>threat</th>\n","      <th>insult</th>\n","      <th>identity_hate</th>\n","      <th>severe_toxicity</th>\n","      <th>identity_attack</th>\n","      <th>asian</th>\n","      <th>atheist</th>\n","      <th>bisexual</th>\n","      <th>black</th>\n","      <th>buddhist</th>\n","      <th>christian</th>\n","      <th>female</th>\n","      <th>heterosexual</th>\n","      <th>hindu</th>\n","      <th>homosexual_gay_or_lesbian</th>\n","      <th>intellectual_or_learning_disability</th>\n","      <th>jewish</th>\n","      <th>latino</th>\n","      <th>male</th>\n","      <th>muslim</th>\n","      <th>other_disability</th>\n","      <th>other_gender</th>\n","      <th>other_race_or_ethnicity</th>\n","      <th>other_religion</th>\n","      <th>other_sexual_orientation</th>\n","      <th>physical_disability</th>\n","      <th>psychiatric_or_mental_illness</th>\n","      <th>transgender</th>\n","      <th>white</th>\n","      <th>created_date</th>\n","      <th>publication_id</th>\n","      <th>parent_id</th>\n","      <th>article_id</th>\n","      <th>rating</th>\n","      <th>funny</th>\n","      <th>wow</th>\n","      <th>sad</th>\n","      <th>likes</th>\n","      <th>disagree</th>\n","      <th>sexual_explicit</th>\n","      <th>identity_annotator_count</th>\n","      <th>toxicity_annotator_count</th>\n","      <th>lang</th>\n","      <th>Unnamed: 0</th>\n","      <th>Unnamed: 0.1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0000997932d777bf</td>\n","      <td>Explanation\\nWhy the edits made under my usern...</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>en</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000103f0d9cfb60f</td>\n","      <td>D'aww! He matches this background colour I'm s...</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>en</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>000113f07ec002fd</td>\n","      <td>Hey man, I'm really not trying to edit war. It...</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>en</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0001b41b1c6bb37e</td>\n","      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>en</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0001d958c54c6e35</td>\n","      <td>You, sir, are my hero. Any chance you remember...</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>en</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>223389</th>\n","      <td>ffeb7faf9662ed0f</td>\n","      <td>(UTC)\\n\\n :: FYI, atualmente estou em conflito...</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>pt</td>\n","      <td>223544.0</td>\n","      <td>223544.0</td>\n","    </tr>\n","    <tr>\n","      <th>223390</th>\n","      <td>ffe3a3e2d8f0eb9b</td>\n","      <td>Esta é a minha sandbox da página de discussão ...</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>pt</td>\n","      <td>223545.0</td>\n","      <td>223545.0</td>\n","    </tr>\n","    <tr>\n","      <th>223391</th>\n","      <td>ffebe90c8d5acaba</td>\n","      <td>\"\\n\\n == IRAN ==\\n Isso mesmo, Irã. Foi o noss...</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>pt</td>\n","      <td>223546.0</td>\n","      <td>223546.0</td>\n","    </tr>\n","    <tr>\n","      <th>223392</th>\n","      <td>fff23c3e174e895e</td>\n","      <td>\"\\n li esta página de discussão e fiquei impre...</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>pt</td>\n","      <td>223547.0</td>\n","      <td>223547.0</td>\n","    </tr>\n","    <tr>\n","      <th>223393</th>\n","      <td>fff3ae2e177b6bb3</td>\n","      <td>\"\\n\\n == Mesma cafeteria? ==\\n\\n Minha memória...</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>pt</td>\n","      <td>223548.0</td>\n","      <td>223548.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3149081 rows × 50 columns</p>\n","</div>"],"text/plain":["                      id  ... Unnamed: 0.1\n","0       0000997932d777bf  ...          NaN\n","1       000103f0d9cfb60f  ...          NaN\n","2       000113f07ec002fd  ...          NaN\n","3       0001b41b1c6bb37e  ...          NaN\n","4       0001d958c54c6e35  ...          NaN\n","...                  ...  ...          ...\n","223389  ffeb7faf9662ed0f  ...     223544.0\n","223390  ffe3a3e2d8f0eb9b  ...     223545.0\n","223391  ffebe90c8d5acaba  ...     223546.0\n","223392  fff23c3e174e895e  ...     223547.0\n","223393  fff3ae2e177b6bb3  ...     223548.0\n","\n","[3149081 rows x 50 columns]"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"B1cRb0P9I9RZ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592652926995,"user_tz":-120,"elapsed":268200,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}}},"source":["input_cols_dev = ['comment_text']\n","\n","train_dataset = models.DatasetRetriever(\n","    tokenizer,\n","    labels_or_ids=train['toxic'].values, \n","    comment_texts=train[input_cols_dev].values, \n","    langs=train['lang'].values,\n","    open_subtitles_path=data_dir/open_subtitles_file,\n","    maxlen=MAX_LENGTH,\n","    use_train_transforms=True,\n",")\n","\n","del train\n","gc.collect();"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TqqeU_P2b08e","colab":{},"executionInfo":{"status":"ok","timestamp":1592653041645,"user_tz":-120,"elapsed":382847,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}}},"source":["validation_tune_dataset = models.DatasetRetriever(\n","    tokenizer,\n","    labels_or_ids=valid['toxic'].values, \n","    comment_texts=valid[input_cols_dev].values, \n","    langs=valid['lang'].values,\n","    open_subtitles_path=data_dir/open_subtitles_file,\n","    maxlen=MAX_LENGTH,\n","    use_train_transforms=True,\n",")\n","\n","valid = clean.clean_data(valid, input_cols_dev, True)\n","\n","validation_dataset = models.DatasetRetriever(\n","    tokenizer,\n","    labels_or_ids=valid['toxic'].values, \n","    comment_texts=valid[input_cols_dev].values, \n","    langs=valid['lang'].values,\n","    maxlen=MAX_LENGTH,\n","    use_train_transforms=False,\n",")\n","\n","del valid\n","gc.collect();"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"j07T9T8uelmN","colab":{},"executionInfo":{"status":"ok","timestamp":1592653041649,"user_tz":-120,"elapsed":382848,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}}},"source":["# input_cols_test = ['content']\n","# test = clean.clean_data(test, input_cols_test)\n","\n","# test_dataset = models.DatasetRetriever(\n","#     tokenizer,\n","#     labels_or_ids=test.index.values, \n","#     comment_texts=test[input_cols_test].values, \n","#     langs=test['lang'].values,\n","#     maxlen=MAX_LENGTH,\n","#     use_train_transforms=False,\n","#     test=True\n","# )"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"7DV-gT6vWA1T","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592653086376,"user_tz":-120,"elapsed":427570,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}}},"source":["backbone_config = AutoConfig.from_pretrained(MODEL, output_hidden_states=output_hidden_states)\n","transformer = AutoModel.from_pretrained(MODEL, config=backbone_config)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"X5bp-Wtuw0ZI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592653086380,"user_tz":-120,"elapsed":427568,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}},"outputId":"dc532652-4283-4a13-c8b0-8e919183c71d"},"source":["net = models.ToxicSimpleNNModel(transformer, config.TrainGlobalConfig)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Multisample dropout is used.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o6VGXhu1WVuy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592653086382,"user_tz":-120,"elapsed":427563,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}},"outputId":"4cccacec-40c1-40c1-e8e8-b9e43d65d854"},"source":["net"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ToxicSimpleNNModel(\n","  (backbone): XLMRobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(250002, 1024, padding_idx=1)\n","      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 1024)\n","      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (12): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (13): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (14): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (15): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (16): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (17): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (18): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (19): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (20): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (21): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (22): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (23): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.2, inplace=False)\n","  (high_dropout): Dropout(p=0.5, inplace=False)\n","  (custom_linear_classifier): Linear(in_features=1024, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"3_AcoTxMw4Bo","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592653086383,"user_tz":-120,"elapsed":427558,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}}},"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","def _mp_fn(rank, flags):\n","    device = xm.xla_device()\n","    net.to(device)\n","\n","    external_sampler = DistributedSamplerWrapper(\n","        sampler=BalanceClassSampler(labels=external_dataset.get_labels(), mode=\"downsampling\"),\n","        num_replicas=xm.xrt_world_size(),\n","        rank=xm.get_ordinal(),\n","        shuffle=True\n","    )\n","    external_loader = torch.utils.data.DataLoader(\n","        external_dataset,\n","        batch_size=config.TrainGlobalConfig.batch_size,\n","        sampler=external_sampler,\n","        pin_memory=False,\n","        drop_last=True,\n","        num_workers=config.TrainGlobalConfig.num_workers,\n","    )\n","\n","    train_sampler = DistributedSamplerWrapper(\n","        sampler=BalanceClassSampler(labels=train_dataset.get_labels(), mode=\"downsampling\"),\n","        num_replicas=xm.xrt_world_size(),\n","        rank=xm.get_ordinal(),\n","        shuffle=True\n","    )\n","    train_loader = torch.utils.data.DataLoader(\n","        train_dataset,\n","        batch_size=config.TrainGlobalConfig.batch_size,\n","        sampler=train_sampler,\n","        pin_memory=False,\n","        drop_last=True,\n","        num_workers=config.TrainGlobalConfig.num_workers,\n","    )\n","    validation_sampler = torch.utils.data.distributed.DistributedSampler(\n","        validation_dataset,\n","        num_replicas=xm.xrt_world_size(),\n","        rank=xm.get_ordinal(),\n","        shuffle=False\n","    )\n","    validation_loader = torch.utils.data.DataLoader(\n","        validation_dataset,\n","        batch_size=config.TrainGlobalConfig.batch_size,\n","        sampler=validation_sampler,\n","        pin_memory=False,\n","        drop_last=False,\n","        num_workers=config.TrainGlobalConfig.num_workers\n","    )\n","    validation_tune_sampler = torch.utils.data.distributed.DistributedSampler(\n","        validation_tune_dataset,\n","        num_replicas=xm.xrt_world_size(),\n","        rank=xm.get_ordinal(),\n","        shuffle=True\n","    )\n","    validation_tune_loader = torch.utils.data.DataLoader(\n","        validation_tune_dataset,\n","        batch_size=config.TrainGlobalConfig.batch_size,\n","        sampler=validation_tune_sampler,\n","        pin_memory=False,\n","        drop_last=False,\n","        num_workers=config.TrainGlobalConfig.num_workers\n","    )\n","    # test_sampler = torch.utils.data.distributed.DistributedSampler(\n","    #     test_dataset,\n","    #     num_replicas=xm.xrt_world_size(),\n","    #     rank=xm.get_ordinal(),\n","    #     shuffle=False\n","    # )\n","    # test_loader = torch.utils.data.DataLoader(\n","    #     test_dataset,\n","    #     batch_size=config.TrainGlobalConfig.batch_size,\n","    #     sampler=test_sampler,\n","    #     pin_memory=False,\n","    #     drop_last=False,\n","    #     num_workers=config.TrainGlobalConfig.num_workers\n","    # )\n","    if rank == 0:\n","        time.sleep(1)\n","    \n","    config.TrainGlobalConfig.train_lenght = len(train_dataset)\n","    fitter = models.TPUFitter(model=net, device=device, config=config.TrainGlobalConfig, \n","                              base_model_path=model_base_dir, model_name=MODEL, model_prefix=MODEL_PREFIX, \n","                              model_version=MODEL_VERSION, out_path=out_dir, log_path=model_dir)\n","    fitter.fit(train_loader, validation_loader)\n","    # Tune the model with validation data (cleaned in the same way with validation data)\n","    fitter.run_validation_tuning(validation_loader, validation_tune_loader, config.TrainGlobalConfig.n_val_epoch)\n","    # xm.master_print(f'Tuning on external data: {val_epoch}')\n","    # fitter.run_validation_tuning(external_loader, val_epoch)\n","    # fitter.run_pseudolabeling(test_loader, val_epoch)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"qY4gmK7QWmkK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592667007391,"user_tz":-120,"elapsed":88323,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}},"outputId":"538104fa-a072-453c-e797-34e53152c4e0"},"source":["FLAGS={}\n","xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')"],"execution_count":23,"outputs":[{"output_type":"stream","text":["TPUFitter started to initilized.\n","**** Directory structure created ****\n","Optimizer and scheduler started to initilized.\n","Number of training steps: 98408\n","Fitter prepared. Device is xla:1\n","**** Fitting process has been started ****\n","\n","2020-06-20T11:39:41.898198\n","LR: 0.0 \n","Epoch:0\n","**** Epoch training has started: 0 ****\n","Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.72386\n","Train Step 50, loss: 0.69312, final_score: 0.50749, time: 323.37109\n","Train Step 100, loss: 0.69406, final_score: 0.50348, time: 390.79306\n","Train Step 150, loss: 0.69484, final_score: 0.49517, time: 458.20658\n","Train Step 200, loss: 0.69234, final_score: 0.51701, time: 525.72463\n","Train Step 250, loss: 0.68923, final_score: 0.54024, time: 592.70205\n","Train Step 300, loss: 0.67974, final_score: 0.58431, time: 659.86913\n","Train Step 350, loss: 0.66100, final_score: 0.64063, time: 727.25311\n","Train Step 400, loss: 0.62769, final_score: 0.69966, time: 794.70554\n","Train Step 450, loss: 0.59737, final_score: 0.74581, time: 862.45378\n","Train Step 500, loss: 0.57383, final_score: 0.77804, time: 930.09575\n","Train Step 550, loss: 0.55231, final_score: 0.80630, time: 997.70077\n","Train Step 600, loss: 0.53744, final_score: 0.82403, time: 1065.38728\n","Train Step 650, loss: 0.52226, final_score: 0.84118, time: 1133.52533\n","Train Step 700, loss: 0.51017, final_score: 0.85412, time: 1201.20543\n","Train Step 750, loss: 0.50070, final_score: 0.86392, time: 1269.04297\n","Train Step 800, loss: 0.49059, final_score: 0.87382, time: 1336.59363\n","Train Step 850, loss: 0.48222, final_score: 0.88150, time: 1404.58280\n","Train Step 900, loss: 0.47445, final_score: 0.88845, time: 1472.33868\n","Train Step 950, loss: 0.46661, final_score: 0.89523, time: 1539.95469\n","Train Step 1000, loss: 0.45989, final_score: 0.90066, time: 1607.83199\n","Train Step 1050, loss: 0.45333, final_score: 0.90604, time: 1675.60212\n","Train Step 1100, loss: 0.44888, final_score: 0.90964, time: 1743.27633\n","Train Step 1150, loss: 0.44474, final_score: 0.91292, time: 1811.20926\n","Train Step 1200, loss: 0.44074, final_score: 0.91586, time: 1879.43650\n","Train Step 1250, loss: 0.43689, final_score: 0.91870, time: 1947.60206\n","Train Step 1300, loss: 0.43289, final_score: 0.92164, time: 2015.65480\n","Train Step 1350, loss: 0.42968, final_score: 0.92390, time: 2083.52170\n","Train Step 1400, loss: 0.42579, final_score: 0.92656, time: 2151.41082\n","Train Step 1450, loss: 0.42271, final_score: 0.92861, time: 2219.42583\n","Train Step 1500, loss: 0.41958, final_score: 0.93063, time: 2287.74137\n","Train Step 1550, loss: 0.41700, final_score: 0.93221, time: 2355.74293\n","Train Step 1600, loss: 0.41465, final_score: 0.93376, time: 2423.13199\n","Train Step 1650, loss: 0.41250, final_score: 0.93517, time: 2490.89967\n","Train Step 1700, loss: 0.41105, final_score: 0.93609, time: 2559.29902\n","Train Step 1750, loss: 0.40941, final_score: 0.93712, time: 2627.38500\n","Train Step 1800, loss: 0.40676, final_score: 0.93869, time: 2695.60853\n","Train Step 1850, loss: 0.40479, final_score: 0.93987, time: 2763.96027\n","Train Step 1900, loss: 0.40276, final_score: 0.94102, time: 2832.05502\n","Train Step 1950, loss: 0.40133, final_score: 0.94187, time: 2900.41759\n","Train Step 2000, loss: 0.39924, final_score: 0.94304, time: 2969.16133\n","Train Step 2050, loss: 0.39786, final_score: 0.94381, time: 3037.50734\n","Train Step 2100, loss: 0.39662, final_score: 0.94450, time: 3105.86662\n","Train Step 2150, loss: 0.39488, final_score: 0.94549, time: 3173.95409\n","Train Step 2200, loss: 0.39409, final_score: 0.94591, time: 3241.94897\n","Train Step 2250, loss: 0.39328, final_score: 0.94639, time: 3310.06254\n","Train Step 2300, loss: 0.39191, final_score: 0.94717, time: 3378.44173\n","[RESULT]: Train. Epoch: 0, loss: 0.39175, final_score: 0.94726, time: 3405.58286\n","Swapping SWA weights for validation\n","**** Validation process has been started ****\n","Valid Step 0, loss: 0.00000, final_score: 0.00000, time: 0.00098\n","Valid Step 50, loss: 0.44830, final_score: 0.95570, time: 76.80994\n","[RESULT]: Validation. Epoch: 0, loss: 0.44706, final_score: 0.95393, best_th: 0.645, time: 150.52380\n","Swapping back to original weights for validation\n","Model has been saved\n","Best model has been updated\n","SWA model weights have been updated\n","\n","2020-06-20T12:40:58.670819\n","LR: 7.990805221446525e-06 \n","Epoch:1\n","**** Epoch training has started: 1 ****\n","Train Step 0, loss: 0.00000, final_score: 0.00000, time: 2.88922\n","Train Step 50, loss: 0.30334, final_score: 0.98423, time: 79.93087\n","Train Step 100, loss: 0.32576, final_score: 0.97510, time: 147.72256\n","Train Step 150, loss: 0.33876, final_score: 0.97068, time: 215.32363\n","Train Step 200, loss: 0.34000, final_score: 0.97046, time: 283.22388\n","Train Step 250, loss: 0.33977, final_score: 0.97070, time: 350.63016\n","Train Step 300, loss: 0.33730, final_score: 0.97146, time: 418.17036\n","Train Step 350, loss: 0.33689, final_score: 0.97169, time: 485.79096\n","Train Step 400, loss: 0.33604, final_score: 0.97189, time: 553.67160\n","Train Step 450, loss: 0.33619, final_score: 0.97158, time: 621.58151\n","Train Step 500, loss: 0.33505, final_score: 0.97180, time: 689.78255\n","Train Step 550, loss: 0.33422, final_score: 0.97213, time: 757.92626\n","Train Step 600, loss: 0.33512, final_score: 0.97164, time: 825.81139\n","Train Step 650, loss: 0.33319, final_score: 0.97232, time: 893.37867\n","Train Step 700, loss: 0.33280, final_score: 0.97262, time: 961.58221\n","Train Step 750, loss: 0.33193, final_score: 0.97311, time: 1029.27392\n","Train Step 800, loss: 0.33199, final_score: 0.97317, time: 1097.50657\n","Train Step 850, loss: 0.33214, final_score: 0.97310, time: 1165.48138\n","Train Step 900, loss: 0.33099, final_score: 0.97353, time: 1234.15124\n","Train Step 950, loss: 0.33235, final_score: 0.97308, time: 1302.02650\n","Train Step 1000, loss: 0.33254, final_score: 0.97300, time: 1369.43243\n","Train Step 1050, loss: 0.33245, final_score: 0.97306, time: 1437.21593\n","Train Step 1100, loss: 0.33330, final_score: 0.97266, time: 1505.12883\n","Train Step 1150, loss: 0.33309, final_score: 0.97281, time: 1573.07835\n","Train Step 1200, loss: 0.33187, final_score: 0.97324, time: 1641.15674\n","Train Step 1250, loss: 0.33176, final_score: 0.97334, time: 1709.27360\n","Train Step 1300, loss: 0.33262, final_score: 0.97294, time: 1777.33903\n","Train Step 1350, loss: 0.33220, final_score: 0.97301, time: 1845.37539\n","Train Step 1400, loss: 0.33215, final_score: 0.97301, time: 1913.81219\n","Train Step 1450, loss: 0.33284, final_score: 0.97268, time: 1982.00642\n","Train Step 1500, loss: 0.33263, final_score: 0.97279, time: 2050.36647\n","Train Step 1550, loss: 0.33196, final_score: 0.97307, time: 2118.72508\n","Train Step 1600, loss: 0.33222, final_score: 0.97297, time: 2186.93360\n","Train Step 1650, loss: 0.33163, final_score: 0.97319, time: 2255.22186\n","Train Step 1700, loss: 0.33176, final_score: 0.97308, time: 2323.30824\n","Train Step 1750, loss: 0.33232, final_score: 0.97288, time: 2391.85675\n","Train Step 1800, loss: 0.33229, final_score: 0.97293, time: 2459.95867\n","Train Step 1850, loss: 0.33190, final_score: 0.97309, time: 2527.94973\n","Train Step 1900, loss: 0.33194, final_score: 0.97307, time: 2596.16547\n","Train Step 1950, loss: 0.33164, final_score: 0.97312, time: 2664.74110\n","Train Step 2000, loss: 0.33135, final_score: 0.97321, time: 2732.89955\n","Train Step 2050, loss: 0.33128, final_score: 0.97327, time: 2801.26364\n","Train Step 2100, loss: 0.33096, final_score: 0.97340, time: 2870.30229\n","Train Step 2150, loss: 0.33099, final_score: 0.97333, time: 2938.61143\n","Train Step 2200, loss: 0.33085, final_score: 0.97339, time: 3007.02052\n","Train Step 2250, loss: 0.33102, final_score: 0.97330, time: 3075.74598\n","Train Step 2300, loss: 0.33066, final_score: 0.97345, time: 3144.09492\n","[RESULT]: Train. Epoch: 1, loss: 0.33049, final_score: 0.97352, time: 3171.44017\n","Swapping SWA weights for validation\n","**** Validation process has been started ****\n","Valid Step 0, loss: 0.00000, final_score: 0.00000, time: 2.63529\n","Valid Step 50, loss: 0.44830, final_score: 0.95570, time: 33.79258\n","[RESULT]: Validation. Epoch: 1, loss: 0.44706, final_score: 0.95393, best_th: 0.645, time: 41.56516\n","Swapping back to original weights for validation\n","\n","2020-06-20T13:34:31.699156\n","LR: 7.95972164388554e-06 \n","Epoch:2\n","**** Epoch training has started: 2 ****\n","Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.75009\n","Train Step 50, loss: 0.31953, final_score: 0.97394, time: 77.08185\n","Train Step 100, loss: 0.31361, final_score: 0.97751, time: 144.54921\n","Train Step 150, loss: 0.32064, final_score: 0.97600, time: 211.94606\n","Train Step 200, loss: 0.32149, final_score: 0.97624, time: 279.51808\n","Train Step 250, loss: 0.32433, final_score: 0.97556, time: 347.37670\n","Train Step 300, loss: 0.32806, final_score: 0.97427, time: 415.39763\n","Train Step 350, loss: 0.32850, final_score: 0.97434, time: 483.26034\n","Train Step 400, loss: 0.32897, final_score: 0.97418, time: 550.74283\n","Train Step 450, loss: 0.32856, final_score: 0.97449, time: 618.97395\n","Train Step 500, loss: 0.32763, final_score: 0.97482, time: 686.56899\n","Train Step 550, loss: 0.32730, final_score: 0.97500, time: 754.66046\n","Train Step 600, loss: 0.32671, final_score: 0.97537, time: 822.41276\n","Train Step 650, loss: 0.32684, final_score: 0.97521, time: 890.26005\n","Train Step 700, loss: 0.32548, final_score: 0.97579, time: 958.16485\n","Train Step 750, loss: 0.32629, final_score: 0.97540, time: 1026.40677\n","Train Step 800, loss: 0.32655, final_score: 0.97536, time: 1094.36330\n","Train Step 850, loss: 0.32693, final_score: 0.97535, time: 1162.93979\n","Train Step 900, loss: 0.32729, final_score: 0.97523, time: 1231.22777\n","Train Step 950, loss: 0.32785, final_score: 0.97514, time: 1299.04693\n","Train Step 1000, loss: 0.32767, final_score: 0.97524, time: 1367.27873\n","Train Step 1050, loss: 0.32811, final_score: 0.97501, time: 1435.79709\n","Train Step 1100, loss: 0.32759, final_score: 0.97520, time: 1503.76418\n","Train Step 1150, loss: 0.32742, final_score: 0.97521, time: 1572.09111\n","Train Step 1200, loss: 0.32774, final_score: 0.97512, time: 1640.63147\n","Train Step 1250, loss: 0.32761, final_score: 0.97510, time: 1708.94829\n","Train Step 1300, loss: 0.32717, final_score: 0.97531, time: 1777.42744\n","Train Step 1350, loss: 0.32681, final_score: 0.97540, time: 1845.88882\n","Train Step 1400, loss: 0.32594, final_score: 0.97563, time: 1914.13194\n","Train Step 1450, loss: 0.32595, final_score: 0.97555, time: 1982.19173\n","Train Step 1500, loss: 0.32570, final_score: 0.97562, time: 2050.54365\n","Train Step 1550, loss: 0.32651, final_score: 0.97532, time: 2119.36030\n","Train Step 1600, loss: 0.32670, final_score: 0.97535, time: 2187.96326\n","Train Step 1650, loss: 0.32652, final_score: 0.97544, time: 2256.12562\n","Train Step 1700, loss: 0.32616, final_score: 0.97558, time: 2324.81392\n","Train Step 1750, loss: 0.32612, final_score: 0.97566, time: 2393.31423\n","Train Step 1800, loss: 0.32584, final_score: 0.97569, time: 2461.89420\n","Train Step 1850, loss: 0.32616, final_score: 0.97553, time: 2530.35770\n","Train Step 1900, loss: 0.32579, final_score: 0.97565, time: 2598.69287\n","Train Step 1950, loss: 0.32547, final_score: 0.97576, time: 2667.00748\n","Train Step 2000, loss: 0.32576, final_score: 0.97560, time: 2735.15920\n","Train Step 2050, loss: 0.32550, final_score: 0.97570, time: 2803.91168\n","Train Step 2100, loss: 0.32536, final_score: 0.97572, time: 2872.31045\n","Train Step 2150, loss: 0.32535, final_score: 0.97572, time: 2940.76523\n","Train Step 2200, loss: 0.32545, final_score: 0.97563, time: 3009.06611\n","Train Step 2250, loss: 0.32586, final_score: 0.97551, time: 3077.21443\n","Train Step 2300, loss: 0.32546, final_score: 0.97567, time: 3145.38573\n","[RESULT]: Train. Epoch: 2, loss: 0.32547, final_score: 0.97566, time: 3172.81130\n","Swapping SWA weights for validation\n","**** Validation process has been started ****\n","Valid Step 0, loss: 0.00000, final_score: 0.00000, time: 0.67253\n","Valid Step 50, loss: 0.44830, final_score: 0.95570, time: 31.65598\n","[RESULT]: Validation. Epoch: 2, loss: 0.44706, final_score: 0.95393, best_th: 0.645, time: 39.41646\n","Swapping back to original weights for validation\n","\n","2020-06-20T14:28:03.951158\n","LR: 7.906838528092145e-06 \n","Epoch:3\n","**** Epoch training has started: 3 ****\n","Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.86855\n","Train Step 50, loss: 0.32607, final_score: 0.97383, time: 70.22563\n","Train Step 100, loss: 0.31989, final_score: 0.97610, time: 138.25442\n","Train Step 150, loss: 0.32120, final_score: 0.97604, time: 206.35411\n","Train Step 200, loss: 0.32243, final_score: 0.97508, time: 274.08098\n","Train Step 250, loss: 0.31910, final_score: 0.97686, time: 342.28256\n","Train Step 300, loss: 0.32066, final_score: 0.97677, time: 410.20472\n","Train Step 350, loss: 0.32051, final_score: 0.97700, time: 477.75778\n","Train Step 400, loss: 0.31990, final_score: 0.97735, time: 545.84131\n","Train Step 450, loss: 0.32105, final_score: 0.97681, time: 613.88575\n","Train Step 500, loss: 0.32247, final_score: 0.97633, time: 681.66007\n","Train Step 550, loss: 0.32349, final_score: 0.97605, time: 749.46865\n","Train Step 600, loss: 0.32321, final_score: 0.97622, time: 817.66315\n","Train Step 650, loss: 0.32212, final_score: 0.97656, time: 885.95794\n","Train Step 700, loss: 0.32241, final_score: 0.97635, time: 954.23312\n","Train Step 750, loss: 0.32167, final_score: 0.97671, time: 1022.34730\n","Train Step 800, loss: 0.32171, final_score: 0.97649, time: 1090.68776\n","Train Step 850, loss: 0.32095, final_score: 0.97683, time: 1158.58205\n","Train Step 900, loss: 0.32034, final_score: 0.97713, time: 1226.22632\n","Train Step 950, loss: 0.32017, final_score: 0.97720, time: 1294.16528\n","Train Step 1000, loss: 0.32047, final_score: 0.97706, time: 1362.45180\n","Train Step 1050, loss: 0.32001, final_score: 0.97729, time: 1430.76193\n","Train Step 1100, loss: 0.32024, final_score: 0.97719, time: 1499.03369\n","Train Step 1150, loss: 0.32035, final_score: 0.97709, time: 1567.25891\n","Train Step 1200, loss: 0.32100, final_score: 0.97683, time: 1634.99195\n","Train Step 1250, loss: 0.32169, final_score: 0.97663, time: 1703.40587\n","Train Step 1300, loss: 0.32187, final_score: 0.97649, time: 1771.59716\n","Train Step 1350, loss: 0.32179, final_score: 0.97652, time: 1840.10551\n","Train Step 1400, loss: 0.32150, final_score: 0.97661, time: 1907.85368\n","Train Step 1450, loss: 0.32209, final_score: 0.97640, time: 1976.31966\n","Train Step 1500, loss: 0.32184, final_score: 0.97651, time: 2044.34742\n","Train Step 1550, loss: 0.32190, final_score: 0.97653, time: 2112.78460\n","Train Step 1600, loss: 0.32213, final_score: 0.97651, time: 2181.01910\n","Train Step 1650, loss: 0.32253, final_score: 0.97643, time: 2249.24177\n","Train Step 1700, loss: 0.32209, final_score: 0.97661, time: 2317.42022\n","Train Step 1750, loss: 0.32191, final_score: 0.97665, time: 2385.60215\n","Train Step 1800, loss: 0.32237, final_score: 0.97652, time: 2454.20339\n","Train Step 1850, loss: 0.32291, final_score: 0.97639, time: 2522.84273\n","Train Step 1900, loss: 0.32307, final_score: 0.97629, time: 2590.86145\n","Train Step 1950, loss: 0.32288, final_score: 0.97634, time: 2658.89138\n","Train Step 2000, loss: 0.32248, final_score: 0.97655, time: 2726.88676\n","Train Step 2050, loss: 0.32240, final_score: 0.97657, time: 2794.96995\n","Train Step 2100, loss: 0.32209, final_score: 0.97663, time: 2863.40348\n","Train Step 2150, loss: 0.32239, final_score: 0.97658, time: 2931.76924\n","Train Step 2200, loss: 0.32242, final_score: 0.97657, time: 3000.00041\n","Train Step 2250, loss: 0.32216, final_score: 0.97661, time: 3068.10412\n","Train Step 2300, loss: 0.32227, final_score: 0.97650, time: 3136.57568\n","[RESULT]: Train. Epoch: 3, loss: 0.32210, final_score: 0.97660, time: 3164.02903\n","Swapping SWA weights for validation\n","**** Validation process has been started ****\n","Valid Step 0, loss: 0.00000, final_score: 0.00000, time: 0.66712\n","Valid Step 50, loss: 0.44830, final_score: 0.95570, time: 31.68898\n","[RESULT]: Validation. Epoch: 3, loss: 0.44706, final_score: 0.95393, best_th: 0.645, time: 39.46525\n","Swapping back to original weights for validation\n","******Validation tuning is started*****\n","**** Fitting process has been started ****\n","\n","2020-06-20T15:21:27.478194\n","LR: 7.832447012587748e-06 \n","Epoch:0\n","**** Epoch training has started: 0 ****\n","Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.09185\n","Train Step 50, loss: 0.34770, final_score: 0.93590, time: 68.86405\n","[RESULT]: Train. Epoch: 4, loss: 0.33605, final_score: 0.94356, time: 227.26052\n","Swapping SWA weights for validation\n","**** Validation process has been started ****\n","Valid Step 0, loss: 0.00000, final_score: 0.00000, time: 0.37347\n","Valid Step 50, loss: 0.44830, final_score: 0.95570, time: 31.32126\n","[RESULT]: Validation. Epoch: 4, loss: 0.44706, final_score: 0.95393, best_th: 0.645, time: 39.07004\n","Swapping back to original weights for validation\n","\n","2020-06-20T15:25:53.841402\n","LR: 7.830130526758912e-06 \n","Epoch:1\n","**** Epoch training has started: 1 ****\n","Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.08357\n","Train Step 50, loss: 0.32711, final_score: 0.95515, time: 69.20509\n","[RESULT]: Train. Epoch: 5, loss: 0.31934, final_score: 0.96006, time: 86.85841\n","Swapping SWA weights for validation\n","**** Validation process has been started ****\n","Valid Step 0, loss: 0.00000, final_score: 0.00000, time: 0.26829\n","Valid Step 50, loss: 0.44830, final_score: 0.95570, time: 31.25877\n","[RESULT]: Validation. Epoch: 5, loss: 0.44706, final_score: 0.95393, best_th: 0.645, time: 39.02072\n","Swapping back to original weights for validation\n","\n","2020-06-20T15:27:59.747777\n","LR: 7.82779848483681e-06 \n","Epoch:2\n","**** Epoch training has started: 2 ****\n","Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.08249\n","Train Step 50, loss: 0.32453, final_score: 0.95419, time: 69.83831\n","[RESULT]: Train. Epoch: 6, loss: 0.31907, final_score: 0.95827, time: 87.46950\n","Swapping SWA weights for validation\n","**** Validation process has been started ****\n","Valid Step 0, loss: 0.00000, final_score: 0.00000, time: 0.29040\n","Valid Step 50, loss: 0.44830, final_score: 0.95570, time: 31.42528\n","[RESULT]: Validation. Epoch: 6, loss: 0.44706, final_score: 0.95393, best_th: 0.645, time: 39.22043\n","Swapping back to original weights for validation\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IAhfU9BSod0f","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592667258773,"user_tz":-120,"elapsed":55316,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}}},"source":["tokenizer.save_pretrained(model_dir)\n","transformer.save_pretrained(model_dir)"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"yitXZLNHSlzw","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592667261066,"user_tz":-120,"elapsed":2281,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}}},"source":["config_path = (model_dir/\"config.json\")\n","# add model metadata for inference step\n","model_metadata = {'model_name': MODEL, \"model_prefix\": MODEL_PREFIX, \"model_version\": MODEL_VERSION, \n","                  \"max_len\": MAX_LENGTH, \"english pipeline\": english_pipeline}\n","\n","with open(config_path) as f:\n","    data = json.load(f)\n","\n","data.update(model_metadata)\n","\n","with open(config_path, 'w') as f:\n","    json.dump(data, f, indent=3, sort_keys=True)"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"fblcKnLPIRnT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592667265635,"user_tz":-120,"elapsed":6842,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}}},"source":["with open(Path(root_dir, \"credentials/kaggle.json\")) as cred_json:\n","    creds = json.load(cred_json)\n","\n","os.environ[\"KAGGLE_USERNAME\"] = creds['username']\n","os.environ[\"KAGGLE_KEY\"] = creds['key']\n","\n","from kaggle.api.kaggle_api_extended import KaggleApi\n","new_model = {\n","  \"title\": f\"{MODEL}\", \n","  \"description\": \"Trained model for toxic comment challange\",\n","  \"id\": f\"quanncore/{MODEL.lower()}\", \n","  \"licenses\": [{\"name\": \"CC0-1.0\"}],\n","  \"resources\": [\n","    {\n","      \"path\": \"best_model.bin\",\n","      \"description\": \"Saved model file\"\n","    },\n","    {\n","      \"path\": \"sentencepiece.bpe.model\",\n","      \"description\": \"sentencepiece model\"\n","    },\n","    {\n","      \"path\": \"special_tokens_map.json\",\n","      \"description\": \"Special token map\"\n","    },\n","    {\n","      \"path\": \"log.txt\",\n","      \"description\": \"Log file of trained model\"\n","    },\n","    {\n","      \"path\": \"tokenizer_config.json\",\n","      \"description\": \"Tokenizer config\"\n","    },\n","    {\n","      \"path\": \"config.json\",\n","      \"description\": \"Model config\"\n","    }\n","  ],\n","}\n","\n","def update_model_kaggle():\n","  api = KaggleApi()\n","  api.authenticate()\n","\n","  dataset_id = f\"quanncore/{MODEL.lower()}\"\n","  with open((model_dir/'dataset-metadata.json'), 'w') as fp:\n","    json.dump(new_model, fp)\n","  \n","  response = api.dataset_status(dataset_id)\n","  if response == None:\n","    print('Creating a new dataset\\n')\n","    api.dataset_create_new(model_dir)\n","  else:\n","    print(f'Got response: {response}\\n. Creating a new version\\n')\n","    api.dataset_create_version(model_dir, version_notes=f'new version: {MODEL_VERSION.lower()}')"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"xkCL1xJS0aZV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":451},"executionInfo":{"status":"ok","timestamp":1592669981356,"user_tz":-120,"elapsed":80127,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}},"outputId":"b01664c6-b4d3-4004-e6fd-f4ad5a98e049"},"source":["update_model_kaggle()"],"execution_count":27,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0.00/16.0 [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Got response: ready\n",". Creating a new version\n","\n","Skipping folder: .ipynb_checkpoints; use '--dir-mode' to upload folders\n","Starting upload for file tokenizer_config.json\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 16.0/16.0 [00:01<00:00, 13.3B/s]\n","  0%|          | 0.00/150 [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: tokenizer_config.json (16B)\n","Starting upload for file special_tokens_map.json\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 150/150 [00:00<00:00, 188B/s]\n","  0%|          | 0.00/4.83M [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: special_tokens_map.json (150B)\n","Starting upload for file sentencepiece.bpe.model\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 4.83M/4.83M [00:02<00:00, 2.38MB/s]\n","  0%|          | 0.00/2.09G [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: sentencepiece.bpe.model (5MB)\n","Starting upload for file pytorch_model.bin\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 2.09G/2.09G [00:30<00:00, 73.6MB/s]\n","  0%|          | 0.00/1.21k [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: pytorch_model.bin (2GB)\n","Starting upload for file config.json\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1.21k/1.21k [00:01<00:00, 636B/s]\n","  0%|          | 0.00/2.09G [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: config.json (1KB)\n","Starting upload for file best_model.bin\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 2.09G/2.09G [00:37<00:00, 59.6MB/s]\n","  0%|          | 0.00/157k [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: best_model.bin (2GB)\n","Starting upload for file log.txt\n"],"name":"stdout"},{"output_type":"stream","text":["\r100%|██████████| 157k/157k [00:01<00:00, 136kB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Upload successful: log.txt (157KB)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zdKvaU4Mqi92","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"status":"ok","timestamp":1592945089434,"user_tz":-120,"elapsed":4177,"user":{"displayName":"baran nama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQrWpbpPLQNGzzlH--rRpMzxfIcUpufW1agNdj=s64","userId":"13813923297410055782"}},"outputId":"820fd5cc-4303-42d4-eba1-00d3a476480b"},"source":["%cd \"{root_dir}\"\n","!git status"],"execution_count":1,"outputs":[{"output_type":"stream","text":["[Errno 2] No such file or directory: '{root_dir}'\n","/content\n","fatal: not a git repository (or any of the parent directories): .git\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wX5tE4yiqpE3","colab_type":"code","colab":{}},"source":["!git add ."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5WrWqutYqrwt","colab_type":"code","colab":{}},"source":["# todo: please fill the lb score after making submission\n","git_comment = f'Model: {MODEL} Version: {MODEL_VERSION} Kaggle LB Score: {0.9301}'\n","!git commit -m \"{git_comment}\" -F \"changes.txt\"\n","!git config --global user.email \"{GIT_EMAIL}\"\n","!git config --global user.name \"{GIT_USERNAME}\"\n","!git push origin master"],"execution_count":null,"outputs":[]}]}