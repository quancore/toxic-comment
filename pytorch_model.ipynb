{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOTie8mrp11WWdVXzVKTWQ7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quancore/toxic-comment/blob/master/pytorch_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsZb7QICuRIe",
        "colab_type": "code",
        "outputId": "0eae428c-0f53-491b-fac8-ee81f75de659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py > /dev/null\n",
        "!python pytorch-xla-env-setup.py --version 20200420 --apt-packages libomp5 libopenblas-dev > /dev/null\n",
        "!pip install transformers==2.5.1 > /dev/null\n",
        "!pip install pandarallel > /dev/null\n",
        "!pip install catalyst==20.4.2 > /dev/null\n",
        "!pip install kaggle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  3727  100  3727    0     0  63169      0 --:--:-- --:--:-- --:--:-- 63169\n",
            "Copying gs://tpu-pytorch/wheels/torch-nightly+20200420-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][ 86.8 MiB/ 86.8 MiB]                                                \n",
            "Operation completed over 1 objects/86.8 MiB.                                     \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200420-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][117.2 MiB/117.2 MiB]                                                \n",
            "Operation completed over 1 objects/117.2 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200420-cp36-cp36m-linux_x86_64.whl...\n",
            "/ [1 files][  2.4 MiB/  2.4 MiB]                                                \n",
            "Operation completed over 1 objects/2.4 MiB.                                      \n",
            "\u001b[31mERROR: fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: catalyst 20.4.2 requires torchvision>=0.2.1, which is not installed.\u001b[0m\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.9)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfxkXZQf1nLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# arr=[]\n",
        "# while(1):\n",
        "#  arr.append(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIWDJmzxhtM9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "6983039d-0c1b-4f31-feba-8eda088abe37"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2 \n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "import sys\n",
        "sys.path.append('drive/My Drive/toxic_comment/scripts')\n",
        "\n",
        "import os\n",
        "os.environ['XLA_USE_BF16'] = \"1\"\n",
        "\n",
        "import gc\n",
        "import time\n",
        "from pathlib import Path\n",
        "from importlib import reload\n",
        "\n",
        "import utility as utils\n",
        "import albumentations as alb\n",
        "import data_cleaning as clean\n",
        "import models\n",
        "import config\n",
        "\n",
        "reload(utils)\n",
        "reload(alb)\n",
        "reload(clean)\n",
        "reload(models)\n",
        "reload(config)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "from pandarallel import pandarallel\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "from catalyst.data.sampler import DistributedSamplerWrapper, BalanceClassSampler\n",
        "\n",
        "pandarallel.initialize(nb_workers=4, progress_bar=False)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "INFO: Pandarallel will run on 4 workers.\n",
            "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9iEdfKAzU0q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL = 'xlm-roberta-large'\n",
        "MODEL_VERSION = 'v1'\n",
        "MAX_LENGTH = 224\n",
        "\n",
        "root_dir = \"drive/My Drive/toxic_comment\"\n",
        "\n",
        "# *Data access\n",
        "data_dir = Path(root_dir, \"data\")\n",
        "data_t_dir = data_dir/\"jigsaw-toxic/translations\"\n",
        "\n",
        "# *Model paths\n",
        "model_dir = Path(root_dir, \"models\")\n",
        "\n",
        "# *Files\n",
        "train_file1 = \"jigsaw-toxic/jigsaw-toxic-comment-train.csv\"\n",
        "train_file2 = \"jigsaw-toxic/jigsaw-unintended-bias-train.csv\"\n",
        "val_file = \"jigsaw-toxic/validation.csv\"\n",
        "test_file = \"jigsaw-toxic/test.csv\"\n",
        "sub_file = \"jigsaw-toxic/sample_submission.csv\"\n",
        "open_subtitles_file = 'open-subtitles-toxic/open-subtitles-synthesic.csv'\n",
        "\n",
        "out_dir = Path(root_dir, 'output')\n",
        "\n",
        "LANGS = {\n",
        "    'en': 'english',\n",
        "    'it': 'italian', \n",
        "    'fr': 'french', \n",
        "    'es': 'spanish',\n",
        "    'tr': 'turkish', \n",
        "    'ru': 'russian',\n",
        "    'pt': 'portuguese'\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-hcJSL1hxdC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "13ea2547-4ed9-4f46-a623-e1202d39b510"
      },
      "source": [
        "%%time\n",
        "# Read the data\n",
        "dir_dict = {'base_dir': data_dir, 'base_t_dir': data_t_dir, 'train_file1': train_file1, \n",
        "            'train_file2': train_file2, 'val_file': val_file, 'test_file': test_file, 'sub_file': sub_file}\n",
        "train, valid, test, sub = utils.read_data(dir_dict, list(LANGS.keys()))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 46.5 s, sys: 7.43 s, total: 53.9 s\n",
            "Wall time: 1min 12s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yoQXP4YPcmP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "b3d08f3a-5a2c-401a-ce32-c40cad7d6d39"
      },
      "source": [
        "train['lang'].hist(bins=20);"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGMtzLCiVuQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1cRb0P9I9RZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = models.DatasetRetriever(\n",
        "    tokenizer,\n",
        "    labels_or_ids=train['toxic'].values, \n",
        "    comment_texts=train['comment_text'].values, \n",
        "    langs=train['lang'].values,\n",
        "    lang_dict=LANGS,\n",
        "    open_subtitles_path=data_dir/open_subtitles_file,\n",
        "    maxlen=MAX_LENGTH,\n",
        "    use_train_transforms=True,\n",
        ")\n",
        "\n",
        "del train\n",
        "gc.collect();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TqqeU_P2b08e",
        "colab": {}
      },
      "source": [
        "input_cols_dev = ['comment_text']\n",
        "\n",
        "validation_tune_dataset = models.DatasetRetriever(\n",
        "    tokenizer,\n",
        "    labels_or_ids=valid['toxic'].values, \n",
        "    comment_texts=valid[input_cols_dev].values, \n",
        "    langs=valid['lang'].values,\n",
        "    lang_dict=LANGS,\n",
        "    open_subtitles_path=data_dir/open_subtitles_file,\n",
        "    maxlen=MAX_LENGTH,\n",
        "    use_train_transforms=True,\n",
        ")\n",
        "\n",
        "valid = clean.clean_data(valid, input_cols_dev, LANGS)\n",
        "\n",
        "validation_dataset = models.DatasetRetriever(\n",
        "    tokenizer,\n",
        "    labels_or_ids=valid['toxic'].values, \n",
        "    comment_texts=valid[input_cols_dev].values, \n",
        "    langs=valid['lang'].values,\n",
        "    maxlen=MAX_LENGTH,\n",
        "    use_train_transforms=False,\n",
        ")\n",
        "\n",
        "del valid\n",
        "gc.collect();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j07T9T8uelmN",
        "colab": {}
      },
      "source": [
        "input_cols_test = ['content']\n",
        "test = clean.clean_data(test, input_cols_test, LANGS)\n",
        "\n",
        "test_dataset = models.DatasetRetriever(\n",
        "    tokenizer,\n",
        "    labels_or_ids=test.index.values, \n",
        "    comment_texts=test[input_cols_test].values, \n",
        "    langs=test['lang'].values,\n",
        "    maxlen=MAX_LENGTH,\n",
        "    use_train_transforms=False,\n",
        "    test=True\n",
        ")\n",
        "\n",
        "del test\n",
        "gc.collect();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DV-gT6vWA1T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformer = AutoModel.from_pretrained(MODEL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5bp-Wtuw0ZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = models.ToxicSimpleNNModel(transformer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6VGXhu1WVuy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "29e7b638-2775-4547-bc8d-a2bef7f9bcd0"
      },
      "source": [
        "net"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ToxicSimpleNNModel(\n",
              "  (backbone): XLMRobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(250002, 1024, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (12): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (13): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (14): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (15): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (16): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (17): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (18): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (19): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (20): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (21): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (22): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (23): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (linear): Linear(in_features=2048, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_AcoTxMw4Bo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def _mp_fn(rank, flags):\n",
        "    device = xm.xla_device()\n",
        "    net.to(device)\n",
        "\n",
        "    train_sampler = DistributedSamplerWrapper(\n",
        "        sampler=BalanceClassSampler(labels=train_dataset.get_labels(), mode=\"downsampling\"),\n",
        "        num_replicas=xm.xrt_world_size(),\n",
        "        rank=xm.get_ordinal(),\n",
        "        shuffle=True\n",
        "    )\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=config.TrainGlobalConfig.batch_size,\n",
        "        sampler=train_sampler,\n",
        "        pin_memory=False,\n",
        "        drop_last=True,\n",
        "        num_workers=config.TrainGlobalConfig.num_workers,\n",
        "    )\n",
        "    validation_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "        validation_dataset,\n",
        "        num_replicas=xm.xrt_world_size(),\n",
        "        rank=xm.get_ordinal(),\n",
        "        shuffle=False\n",
        "    )\n",
        "    validation_loader = torch.utils.data.DataLoader(\n",
        "        validation_dataset,\n",
        "        batch_size=config.TrainGlobalConfig.batch_size,\n",
        "        sampler=validation_sampler,\n",
        "        pin_memory=False,\n",
        "        drop_last=False,\n",
        "        num_workers=config.TrainGlobalConfig.num_workers\n",
        "    )\n",
        "    validation_tune_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "        validation_tune_dataset,\n",
        "        num_replicas=xm.xrt_world_size(),\n",
        "        rank=xm.get_ordinal(),\n",
        "        shuffle=True\n",
        "    )\n",
        "    validation_tune_loader = torch.utils.data.DataLoader(\n",
        "        validation_tune_dataset,\n",
        "        batch_size=config.TrainGlobalConfig.batch_size,\n",
        "        sampler=validation_tune_sampler,\n",
        "        pin_memory=False,\n",
        "        drop_last=False,\n",
        "        num_workers=config.TrainGlobalConfig.num_workers\n",
        "    )\n",
        "    test_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "        test_dataset,\n",
        "        num_replicas=xm.xrt_world_size(),\n",
        "        rank=xm.get_ordinal(),\n",
        "        shuffle=False\n",
        "    )\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=config.TrainGlobalConfig.batch_size,\n",
        "        sampler=test_sampler,\n",
        "        pin_memory=False,\n",
        "        drop_last=False,\n",
        "        num_workers=config.TrainGlobalConfig.num_workers\n",
        "    )\n",
        "    if rank == 0:\n",
        "        time.sleep(1)\n",
        "    \n",
        "    fitter = models.TPUFitter(model=net, device=device, config=config.TrainGlobalConfig, \n",
        "                              base_model_path=model_dir, model_name=MODEL, model_version=MODEL_VERSION, out_path=out_dir)\n",
        "    fitter.fit(train_loader, validation_loader)\n",
        "    for val_epoch in range(2):\n",
        "      fitter.run_validation_tuning(validation_tune_loader, val_epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qY4gmK7QWmkK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "caa533d7-4d02-4623-b294-372c0f49be68"
      },
      "source": [
        "FLAGS={}\n",
        "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "**** Directory structure created ****\n",
            "Fitter prepared. Device is xla:1\n",
            "**** Fitting process has been started ****\n",
            "\n",
            "2020-05-14T13:11:51.520004\n",
            "LR: 4e-05 \n",
            "Epoch:0\n",
            "**** Epoch training has started: 0 ****\n",
            "Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.92831\n",
            "Train Step 50, loss: 0.54656, final_score: 0.83387, time: 200.87250\n",
            "Train Step 100, loss: 0.47513, final_score: 0.89875, time: 253.25266\n",
            "Train Step 150, loss: 0.43087, final_score: 0.92735, time: 305.44174\n",
            "Train Step 200, loss: 0.41061, final_score: 0.93877, time: 357.87136\n",
            "Train Step 250, loss: 0.40007, final_score: 0.94435, time: 410.63996\n",
            "Train Step 300, loss: 0.39041, final_score: 0.94888, time: 463.31462\n",
            "Train Step 350, loss: 0.38379, final_score: 0.95208, time: 515.99540\n",
            "Train Step 400, loss: 0.37535, final_score: 0.95585, time: 568.44868\n",
            "Train Step 450, loss: 0.36853, final_score: 0.95891, time: 620.92501\n",
            "Train Step 500, loss: 0.36286, final_score: 0.96133, time: 673.56036\n",
            "Train Step 550, loss: 0.36049, final_score: 0.96225, time: 726.18870\n",
            "Train Step 600, loss: 0.35644, final_score: 0.96391, time: 778.90874\n",
            "Train Step 650, loss: 0.35134, final_score: 0.96585, time: 831.45687\n",
            "Train Step 700, loss: 0.34900, final_score: 0.96665, time: 884.06698\n",
            "Train Step 750, loss: 0.34556, final_score: 0.96808, time: 936.72338\n",
            "Train Step 800, loss: 0.34366, final_score: 0.96883, time: 989.32362\n",
            "Train Step 850, loss: 0.34216, final_score: 0.96930, time: 1042.01467\n",
            "Train Step 900, loss: 0.34014, final_score: 0.97012, time: 1094.51118\n",
            "Train Step 950, loss: 0.33738, final_score: 0.97117, time: 1147.51284\n",
            "Train Step 1000, loss: 0.33619, final_score: 0.97165, time: 1200.18380\n",
            "Train Step 1050, loss: 0.33464, final_score: 0.97223, time: 1252.88476\n",
            "Train Step 1100, loss: 0.33305, final_score: 0.97285, time: 1305.64330\n",
            "Train Step 1150, loss: 0.33112, final_score: 0.97363, time: 1358.28519\n",
            "Train Step 1200, loss: 0.33004, final_score: 0.97394, time: 1410.86332\n",
            "Train Step 1250, loss: 0.32918, final_score: 0.97424, time: 1463.50471\n",
            "Train Step 1300, loss: 0.32793, final_score: 0.97464, time: 1516.10259\n",
            "Train Step 1350, loss: 0.32668, final_score: 0.97512, time: 1568.75229\n",
            "Train Step 1400, loss: 0.32526, final_score: 0.97566, time: 1621.56967\n",
            "Train Step 1450, loss: 0.32451, final_score: 0.97586, time: 1674.40318\n",
            "Train Step 1500, loss: 0.32307, final_score: 0.97640, time: 1727.19605\n",
            "Train Step 1550, loss: 0.32202, final_score: 0.97675, time: 1779.89211\n",
            "Train Step 1600, loss: 0.32095, final_score: 0.97714, time: 1832.69845\n",
            "Train Step 1650, loss: 0.32060, final_score: 0.97725, time: 1885.20328\n",
            "Train Step 1700, loss: 0.32007, final_score: 0.97742, time: 1937.92397\n",
            "Train Step 1750, loss: 0.31993, final_score: 0.97748, time: 1990.83579\n",
            "Train Step 1800, loss: 0.31917, final_score: 0.97778, time: 2043.80572\n",
            "Train Step 1850, loss: 0.31864, final_score: 0.97794, time: 2096.96745\n",
            "Train Step 1900, loss: 0.31829, final_score: 0.97806, time: 2149.79664\n",
            "Train Step 1950, loss: 0.31795, final_score: 0.97816, time: 2202.86012\n",
            "Train Step 2000, loss: 0.31726, final_score: 0.97840, time: 2255.90477\n",
            "Train Step 2050, loss: 0.31699, final_score: 0.97848, time: 2308.76358\n",
            "Train Step 2100, loss: 0.31632, final_score: 0.97870, time: 2361.93105\n",
            "Train Step 2150, loss: 0.31540, final_score: 0.97901, time: 2415.01205\n",
            "Train Step 2200, loss: 0.31447, final_score: 0.97929, time: 2468.09231\n",
            "Train Step 2250, loss: 0.31414, final_score: 0.97939, time: 2521.18469\n",
            "Train Step 2300, loss: 0.31391, final_score: 0.97947, time: 2574.38574\n",
            "[RESULT]: Train. Epoch: 0, loss: 0.31390, final_score: 0.97949, time: 2625.76215\n",
            "Valid Step 0, loss: 0.00000, final_score: 0.00000, time: 0.05134\n",
            "Valid Step 50, loss: 0.45229, final_score: 0.95458, time: 59.64035\n",
            "[RESULT]: Validation. Epoch: 0, loss: 0.45159, final_score: 0.95040, time: 100.03081\n",
            "\n",
            "2020-05-14T13:57:17.328817\n",
            "LR: 4e-05 \n",
            "Epoch:1\n",
            "**** Epoch training has started: 1 ****\n",
            "Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.72228\n",
            "Train Step 50, loss: 0.29443, final_score: 0.98520, time: 53.03809\n",
            "Train Step 100, loss: 0.28835, final_score: 0.98668, time: 105.59182\n",
            "Train Step 150, loss: 0.28448, final_score: 0.98800, time: 158.45042\n",
            "Train Step 200, loss: 0.28299, final_score: 0.98848, time: 211.19035\n",
            "Train Step 250, loss: 0.28563, final_score: 0.98797, time: 264.07528\n",
            "Train Step 300, loss: 0.28544, final_score: 0.98815, time: 316.74573\n",
            "Train Step 350, loss: 0.28745, final_score: 0.98767, time: 369.63264\n",
            "Train Step 400, loss: 0.28713, final_score: 0.98782, time: 422.31917\n",
            "Train Step 450, loss: 0.28749, final_score: 0.98784, time: 474.93288\n",
            "Train Step 500, loss: 0.28899, final_score: 0.98756, time: 527.48863\n",
            "Train Step 550, loss: 0.29045, final_score: 0.98702, time: 579.89922\n",
            "Train Step 600, loss: 0.28912, final_score: 0.98733, time: 632.54112\n",
            "Train Step 650, loss: 0.28953, final_score: 0.98702, time: 685.55527\n",
            "Train Step 700, loss: 0.28890, final_score: 0.98711, time: 738.04327\n",
            "Train Step 750, loss: 0.28899, final_score: 0.98699, time: 791.23438\n",
            "Train Step 800, loss: 0.28916, final_score: 0.98688, time: 844.40404\n",
            "Train Step 850, loss: 0.28905, final_score: 0.98695, time: 897.27935\n",
            "Train Step 900, loss: 0.28909, final_score: 0.98699, time: 950.06734\n",
            "Train Step 950, loss: 0.28897, final_score: 0.98690, time: 1002.91151\n",
            "Train Step 1000, loss: 0.28927, final_score: 0.98691, time: 1055.73980\n",
            "Train Step 1050, loss: 0.28892, final_score: 0.98702, time: 1108.53699\n",
            "Train Step 1100, loss: 0.28964, final_score: 0.98691, time: 1160.94395\n",
            "Train Step 1150, loss: 0.28980, final_score: 0.98677, time: 1213.72246\n",
            "Train Step 1200, loss: 0.28980, final_score: 0.98669, time: 1266.53718\n",
            "Train Step 1250, loss: 0.29015, final_score: 0.98662, time: 1319.39313\n",
            "Train Step 1300, loss: 0.28999, final_score: 0.98676, time: 1372.44418\n",
            "Train Step 1350, loss: 0.28946, final_score: 0.98686, time: 1425.25154\n",
            "Train Step 1400, loss: 0.28893, final_score: 0.98705, time: 1478.34349\n",
            "Train Step 1450, loss: 0.28858, final_score: 0.98710, time: 1531.24966\n",
            "Train Step 1500, loss: 0.28882, final_score: 0.98707, time: 1583.94679\n",
            "Train Step 1550, loss: 0.28857, final_score: 0.98702, time: 1636.89801\n",
            "Train Step 1600, loss: 0.28848, final_score: 0.98705, time: 1689.92186\n",
            "Train Step 1650, loss: 0.28810, final_score: 0.98714, time: 1742.64326\n",
            "Train Step 1700, loss: 0.28822, final_score: 0.98709, time: 1795.45827\n",
            "Train Step 1750, loss: 0.28911, final_score: 0.98680, time: 1848.52938\n",
            "Train Step 1800, loss: 0.28903, final_score: 0.98685, time: 1901.31605\n",
            "Train Step 1850, loss: 0.28920, final_score: 0.98676, time: 1954.43897\n",
            "Train Step 1900, loss: 0.28948, final_score: 0.98672, time: 2007.33215\n",
            "Train Step 1950, loss: 0.28919, final_score: 0.98682, time: 2060.30011\n",
            "Train Step 2000, loss: 0.28923, final_score: 0.98687, time: 2113.16138\n",
            "Train Step 2050, loss: 0.28929, final_score: 0.98680, time: 2166.19161\n",
            "Train Step 2100, loss: 0.28929, final_score: 0.98680, time: 2219.08639\n",
            "Train Step 2150, loss: 0.28924, final_score: 0.98683, time: 2272.25699\n",
            "Train Step 2200, loss: 0.28901, final_score: 0.98686, time: 2325.58511\n",
            "Train Step 2250, loss: 0.28895, final_score: 0.98686, time: 2378.67918\n",
            "Train Step 2300, loss: 0.28895, final_score: 0.98687, time: 2431.98307\n",
            "[RESULT]: Train. Epoch: 1, loss: 0.28895, final_score: 0.98687, time: 2473.53214\n",
            "Valid Step 0, loss: 0.00000, final_score: 0.00000, time: 0.05393\n",
            "Valid Step 50, loss: 0.38986, final_score: 0.95666, time: 23.86931\n",
            "[RESULT]: Validation. Epoch: 1, loss: 0.39122, final_score: 0.95426, time: 29.95302\n",
            "\n",
            "2020-05-14T14:39:07.412387\n",
            "LR: 4e-05 \n",
            "Epoch:2\n",
            "**** Epoch training has started: 2 ****\n",
            "Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.72110\n",
            "Train Step 50, loss: 0.29180, final_score: 0.98582, time: 53.18108\n",
            "Train Step 100, loss: 0.28355, final_score: 0.98865, time: 105.46259\n",
            "Train Step 150, loss: 0.28486, final_score: 0.98766, time: 157.95465\n",
            "Train Step 200, loss: 0.28587, final_score: 0.98747, time: 210.63221\n",
            "Train Step 250, loss: 0.28534, final_score: 0.98769, time: 263.31845\n",
            "Train Step 300, loss: 0.28745, final_score: 0.98720, time: 315.87100\n",
            "Train Step 350, loss: 0.28717, final_score: 0.98743, time: 368.53589\n",
            "Train Step 400, loss: 0.28966, final_score: 0.98664, time: 421.43648\n",
            "Train Step 450, loss: 0.28958, final_score: 0.98651, time: 474.18208\n",
            "Train Step 500, loss: 0.29160, final_score: 0.98594, time: 526.94866\n",
            "Train Step 550, loss: 0.29130, final_score: 0.98588, time: 580.03197\n",
            "Train Step 600, loss: 0.29001, final_score: 0.98611, time: 632.99139\n",
            "Train Step 650, loss: 0.28831, final_score: 0.98652, time: 685.83448\n",
            "Train Step 700, loss: 0.28778, final_score: 0.98667, time: 738.47792\n",
            "Train Step 750, loss: 0.28747, final_score: 0.98666, time: 791.22849\n",
            "Train Step 800, loss: 0.28625, final_score: 0.98705, time: 844.17850\n",
            "Train Step 850, loss: 0.28581, final_score: 0.98728, time: 896.98626\n",
            "Train Step 900, loss: 0.28591, final_score: 0.98722, time: 950.09308\n",
            "Train Step 950, loss: 0.28622, final_score: 0.98711, time: 1003.06316\n",
            "Train Step 1000, loss: 0.28679, final_score: 0.98696, time: 1055.87669\n",
            "Train Step 1050, loss: 0.28692, final_score: 0.98698, time: 1108.69933\n",
            "Train Step 1100, loss: 0.28745, final_score: 0.98686, time: 1161.72779\n",
            "Train Step 1150, loss: 0.28653, final_score: 0.98708, time: 1214.94201\n",
            "Train Step 1200, loss: 0.28657, final_score: 0.98705, time: 1268.11201\n",
            "Train Step 1250, loss: 0.28544, final_score: 0.98728, time: 1321.12500\n",
            "Train Step 1300, loss: 0.28503, final_score: 0.98746, time: 1373.94184\n",
            "Train Step 1350, loss: 0.28540, final_score: 0.98737, time: 1426.56196\n",
            "Train Step 1400, loss: 0.28507, final_score: 0.98738, time: 1479.82556\n",
            "Train Step 1450, loss: 0.28526, final_score: 0.98730, time: 1532.77592\n",
            "Train Step 1500, loss: 0.28492, final_score: 0.98742, time: 1585.77231\n",
            "Train Step 1550, loss: 0.28561, final_score: 0.98729, time: 1638.73633\n",
            "Train Step 1600, loss: 0.28549, final_score: 0.98725, time: 1691.91375\n",
            "Train Step 1650, loss: 0.28484, final_score: 0.98744, time: 1744.91441\n",
            "Train Step 1700, loss: 0.28535, final_score: 0.98730, time: 1798.02086\n",
            "Train Step 1750, loss: 0.28576, final_score: 0.98718, time: 1850.93589\n",
            "Train Step 1800, loss: 0.28554, final_score: 0.98724, time: 1904.11679\n",
            "Train Step 1850, loss: 0.28488, final_score: 0.98743, time: 1957.46629\n",
            "Train Step 1900, loss: 0.28502, final_score: 0.98742, time: 2010.59100\n",
            "Train Step 1950, loss: 0.28539, final_score: 0.98735, time: 2063.87118\n",
            "Train Step 2000, loss: 0.28511, final_score: 0.98742, time: 2117.20855\n",
            "Train Step 2050, loss: 0.28530, final_score: 0.98730, time: 2170.31954\n",
            "Train Step 2100, loss: 0.28552, final_score: 0.98722, time: 2223.55739\n",
            "Train Step 2150, loss: 0.28533, final_score: 0.98726, time: 2276.72241\n",
            "Train Step 2200, loss: 0.28516, final_score: 0.98734, time: 2329.80395\n",
            "Train Step 2250, loss: 0.28559, final_score: 0.98726, time: 2383.16492\n",
            "Train Step 2300, loss: 0.28530, final_score: 0.98735, time: 2436.21479\n",
            "[RESULT]: Train. Epoch: 2, loss: 0.28530, final_score: 0.98735, time: 2484.65379\n",
            "Valid Step 0, loss: 0.00000, final_score: 0.00000, time: 0.04530\n",
            "Valid Step 50, loss: 0.36355, final_score: 0.94839, time: 23.61480\n",
            "[RESULT]: Validation. Epoch: 2, loss: 0.36439, final_score: 0.94885, time: 29.80035\n",
            "**** Epoch training has started: 0 ****\n",
            "Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.09883\n",
            "Train Step 50, loss: 0.33334, final_score: 0.93565, time: 116.23377\n",
            "**** Epoch training has started: 1 ****\n",
            "Train Step 0, loss: 0.00000, final_score: 0.00000, time: 0.00158\n",
            "Train Step 50, loss: 0.30949, final_score: 0.95947, time: 53.23181\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAhfU9BSod0f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "62a2ad92-fce4-4234-89c7-b7e10ec28280"
      },
      "source": [
        "tokenizer.save_pretrained((model_dir/MODEL/MODEL_VERSION))\n",
        "transformer.save_pretrained((model_dir/MODEL/MODEL_VERSION))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('drive/My Drive/toxic_comment/models/xlm-roberta-large/v1/sentencepiece.bpe.model',\n",
              " 'drive/My Drive/toxic_comment/models/xlm-roberta-large/v1/special_tokens_map.json',\n",
              " 'drive/My Drive/toxic_comment/models/xlm-roberta-large/v1/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fblcKnLPIRnT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "c52c1565-ce5c-4296-c5bf-7ae0927724ae"
      },
      "source": [
        "os.environ[\"KAGGLE_USERNAME\"] = creds['username']\n",
        "os.environ[\"KAGGLE_KEY\"] = creds['key']\n",
        "\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "new_model = {\n",
        "  \"title\": f\"{MODEL}\", \n",
        "  \"description\": \"Trained model for toxic comment challange\",\n",
        "  \"id\": f\"quanncore/{MODEL.lower()}\", \n",
        "  \"licenses\": [{\"name\": \"CC0-1.0\"}],\n",
        "  \"resources\": [\n",
        "    {\n",
        "      \"path\": \"last-checkpoint.bin\",\n",
        "      \"description\": \"Saved model file\"\n",
        "    },\n",
        "    {\n",
        "      \"path\": \"sentencepiece.bpe.model\",\n",
        "      \"description\": \"sentencepiece model\"\n",
        "    },\n",
        "    {\n",
        "      \"path\": \"special_tokens_map.json\",\n",
        "      \"description\": \"Special token map\"\n",
        "    },\n",
        "    {\n",
        "      \"path\": \"tokenizer_config.json\",\n",
        "      \"description\": \"Tokenizer config\"\n",
        "    },\n",
        "    {\n",
        "      \"path\": \"config.json\",\n",
        "      \"description\": \"Model config\"\n",
        "    }\n",
        "  ],\n",
        "}\n",
        "\n",
        "def update_model_kaggle():\n",
        "  api = KaggleApi()\n",
        "  api.authenticate()\n",
        "\n",
        "  dataset_dir = (model_dir/MODEL/MODEL_VERSION)\n",
        "  dataset_id = f\"quanncore/{MODEL.lower()}\"\n",
        "  with open((dataset_dir/'dataset-metadata.json'), 'w') as fp:\n",
        "    json.dump(new_model, fp)\n",
        "  \n",
        "  response = api.dataset_status(dataset_id)\n",
        "  if response == None:\n",
        "    print('Creating a new dataset\\n')\n",
        "    api.dataset_create_new(dataset_dir)\n",
        "  else:\n",
        "    print(f'Got response: {response}\\n. Creating a new version\\n')\n",
        "    api.dataset_create_version(dataset_dir, version_notes=f'new version: {MODEL_VERSION.lower()}')\n",
        "\n",
        "\n",
        "\n",
        "update_model_kaggle()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0.00/2.09G [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Got response: ready\n",
            ". Creating a new version\n",
            "\n",
            "Starting upload for file last-checkpoint.bin\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2.09G/2.09G [00:47<00:00, 47.0MB/s]\n",
            "  0%|          | 0.00/39.8k [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload successful: last-checkpoint.bin (2GB)\n",
            "Starting upload for file log.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 39.8k/39.8k [00:01<00:00, 35.4kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload successful: log.txt (40KB)\n",
            "Starting upload for file tokenizer_config.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 16.0/16.0 [00:03<00:00, 5.01B/s]\n",
            "  0%|          | 0.00/150 [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload successful: tokenizer_config.json (16B)\n",
            "Starting upload for file special_tokens_map.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 150/150 [00:01<00:00, 97.8B/s]\n",
            "  0%|          | 0.00/4.83M [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload successful: special_tokens_map.json (150B)\n",
            "Starting upload for file sentencepiece.bpe.model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4.83M/4.83M [00:01<00:00, 4.08MB/s]\n",
            "  0%|          | 0.00/1.02k [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload successful: sentencepiece.bpe.model (5MB)\n",
            "Starting upload for file config.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1.02k/1.02k [00:00<00:00, 1.16kB/s]\n",
            "  0%|          | 0.00/2.09G [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload successful: config.json (1KB)\n",
            "Starting upload for file pytorch_model.bin\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2.09G/2.09G [00:28<00:00, 77.8MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload successful: pytorch_model.bin (2GB)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}